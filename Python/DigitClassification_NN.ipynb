{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DigitClassification-NN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EmecX1x2rXxY",
        "_tW7DKmiwNm5",
        "yLRITkDWxbOu",
        "tTG_z44dxlPW",
        "BkkC5WfY3zyN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCdrpYmmlNyw"
      },
      "source": [
        "# Neural Networks for MNIST database #\r\n",
        "Author: Marco Sousa\r\n",
        "\\\r\n",
        "Last Updated Date: 3/7/2021\r\n",
        "\\\r\n",
        "Details: This is an investigation of applying NN and C-NN onto the MNIST database, further investigating machine Learning for my DSC[499] Capstone assignment at UMass Dartmouth.\r\n",
        "\r\n",
        "Much of the low level design was inspired by [Victor Zhou](https://victorzhou.com/about/) and his posts on [Neural Networks](https://victorzhou.com/blog/intro-to-neural-networks/). Many methods are mostly similar. If I have time, I'd like to return to this implementation to (1) generalize it and (2) change the matrix dimensions in relation to softmax (and its back propagation).\r\n",
        "\r\n",
        "High level design using tensorflow/keras was learned via [TensorFlow](https://www.tensorflow.org/tutorials/keras/classification).\r\n",
        "\r\n",
        "The primary text resource for machine learning and deep learning was by [Goodfellow et. al.](https://www.deeplearningbook.org/).\r\n",
        "\r\n",
        "Below is a linked **Table of Contents:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wfs__e0d8py"
      },
      "source": [
        "### Table of Contents ###\r\n",
        "\r\n",
        "1. [MNIST Dataset](#one)\r\n",
        "    1. Importing and Formatting\r\n",
        "    2. Basic Visualization\r\n",
        "2. [NN](#two)\r\n",
        "3. [C-NN](#three)\r\n",
        "    1. [Motivation for C-NN over NN for Images](#three-one)\r\n",
        "    2. [C-NN Feedforward](#three-two)\r\n",
        "        1. [Convolution](#three-two-one)\r\n",
        "        2. [Maxpool](#three-two-two)\r\n",
        "        3. [Softmax](#three-two-three)\r\n",
        "        4. [Cross-Entropy Loss](#three-two-four)\r\n",
        "        5. [Feedforward Method and Prediction](#three-two-five)\r\n",
        "    3. [Back Propagation and Training](#three-three)\r\n",
        "        1. [Softmax Back Propagation](#three-three-one)\r\n",
        "        2. [Maxpool Back Propagation](#three-three-two)\r\n",
        "        3. [Convolution Back Propagation](#three-three-three)\r\n",
        "        4. [Training with Epochs](#three-three-four)\r\n",
        "        5. [Keras Equivalent of Zhou Implementation](#three-three-five)\r\n",
        "    4. [Official Keras CNN Example](#three-four)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0qfNBI0jH76"
      },
      "source": [
        "### To Do Task List ###\r\n",
        "\r\n",
        "- [x] Github Repo\r\n",
        "- [x] K-Nearest Neighbor\r\n",
        "- [ ] NN Low-Level\r\n",
        "- [ ] NN by Keras/tensorflow\r\n",
        "- [x] Code C-NN Low-Level\r\n",
        "- [x] Convolution Class\r\n",
        "- [x] Maxpool Class\r\n",
        "- [x] Softmax Class\r\n",
        "- [x] Cross Entropy Loss\r\n",
        "- [x] Training C-NN\r\n",
        "- [x] Make predictions for C-NN\r\n",
        "- [x] C-NN by Keras/tensorflow (High-level)\r\n",
        "- [ ] Consider changing the attribute dimensions for softmax and training\r\n",
        "- [ ] Optional: Generalize Convolution Class out of 3x3\r\n",
        "- [ ] Optional: Generalize  Maxpool Class out of 2x2\r\n",
        "- [ ] Optional: Fickleness of input # of features for softmax\r\n",
        "- [ ] Optional: I'd like to make a visualization as it passes feedforward/backprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJtSzzNfo8zS"
      },
      "source": [
        "# MNIST Dataset <a class=\"anchor\" id=\"one\" name=\"one\"></a> #\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smJ5oMqWpvSe"
      },
      "source": [
        "## Importing and Formatting##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTfhEmSrcS7Z"
      },
      "source": [
        "#Importing libraries\r\n",
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "#Machine Learning libraries\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#Visualization libraries\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "#import altair as alt\r\n",
        "\r\n",
        "#Counter dict class\r\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D0Esk3xcTrP"
      },
      "source": [
        "#Importing MNIST data from keras\r\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtqIhnGXcTvy"
      },
      "source": [
        "#Converting to int32; forcing to 0-255 from uint8 causes error when subtraction leads to a negative value\r\n",
        "xTrain = x_train.astype(np.int32)\r\n",
        "yTrain = y_train.astype(np.int32)\r\n",
        "xTest = x_test.astype(np.int32)\r\n",
        "yTest = y_test.astype(np.int32)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmecX1x2rXxY"
      },
      "source": [
        "## Basic Visualization ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0-ttHicgYcb",
        "outputId": "88f9d04b-bfd2-47fb-9495-fc74c9c1afe0"
      },
      "source": [
        "#Printing shape\r\n",
        "print('xTrain: ' + str(xTrain.shape))\r\n",
        "print('yTrain: ' + str(yTrain.shape))\r\n",
        "print('xTest: ' + str(xTest.shape))\r\n",
        "print('yTest: ' + str(yTest.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xTrain: (60000, 28, 28)\n",
            "yTrain: (60000,)\n",
            "xTest: (10000, 28, 28)\n",
            "yTest: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHG-d2kugYeu",
        "outputId": "7668b5b0-9cf0-445f-9c56-6b013255a8a1"
      },
      "source": [
        "#Visualizing the first 16 xTrain digits in a 4 by 4 grid.\r\n",
        "for i in range(1,17):\r\n",
        "  plt.subplot(4,4,i)\r\n",
        "  plt.imshow(xTrain[i-1], cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-LwQ3dVgYhQ",
        "outputId": "1d317cc5-40a8-4b0a-d981-76a8eb8f0d4f"
      },
      "source": [
        "#This of course reflects our yTrain labels on our 28x28 matrix of xTrain\r\n",
        "yTrain[0:16]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM7C9uu4trY_"
      },
      "source": [
        "We observe the label (or digit) distribution. It can be seen that both are mostly uniform. We could prove this with a Chi-Sqaured test, but the following is mostly convincing enough for now. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inHQoNiatEjy",
        "outputId": "fba5ea69-bf50-4b99-d133-12de733d65ce"
      },
      "source": [
        "trainLabelDict = Counter(yTrain)\r\n",
        "trainLabelDict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 5923,\n",
              "         1: 6742,\n",
              "         2: 5958,\n",
              "         3: 6131,\n",
              "         4: 5842,\n",
              "         5: 5421,\n",
              "         6: 5918,\n",
              "         7: 6265,\n",
              "         8: 5851,\n",
              "         9: 5949})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyt5TNKdtEls",
        "outputId": "38b2f144-2f8a-4af2-a81c-080b0503dd0c"
      },
      "source": [
        "plt.bar(range(len(trainLabelDict)), list(trainLabelDict.values()), align='center')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSTGCRKSjQ4-",
        "outputId": "907587b1-8280-4309-f9b1-cd6dfbbcbcf1"
      },
      "source": [
        "testLabelDict = Counter(yTest)\r\n",
        "testLabelDict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 980,\n",
              "         1: 1135,\n",
              "         2: 1032,\n",
              "         3: 1010,\n",
              "         4: 982,\n",
              "         5: 892,\n",
              "         6: 958,\n",
              "         7: 1028,\n",
              "         8: 974,\n",
              "         9: 1009})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gezX-yIEtVpF",
        "outputId": "2691e246-a8f2-467a-ab72-e8e1449e5297"
      },
      "source": [
        "plt.bar(range(len(testLabelDict)), list(testLabelDict.values()), align='center')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS002FFDuYxM"
      },
      "source": [
        "#If we wish to view the raw matrix\r\n",
        "#np.set_printoptions(edgeitems=1,linewidth=500,formatter=dict(float=lambda x: \"%.3g\" %x))\r\n",
        "#xTrain[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etMbz7_sQ4xw"
      },
      "source": [
        "# NN <a class=\"anchor\" id=\"two\" name=\"two\"></a> #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_QdczzhS_dE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdrefnucjQ-w"
      },
      "source": [
        "# C-NN <a  class=\"anchor\" id=\"three\" name=\"three\"></a> #\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tW7DKmiwNm5"
      },
      "source": [
        "## Motivations for C-NN <a class=\"anchor\" id=\"three-one\" name=\"three-one\"></a> ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rOq0lm_vhWk"
      },
      "source": [
        "1. **Large Images:** Consider a larger image. 224x224 in size, with 3 RGB. Thus, we\r\n",
        "have 224x224x3 features, or roughly 150,000 features. If we consider\r\n",
        "many nodes, this is extraordinarily expensive\r\n",
        "2. **Invariances:** Convolution better handles edge shifting, that is, if we slightly transform an image, it still retains its essential identification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OfWgWhkc-Le"
      },
      "source": [
        "The following is a supervised method of C-NN training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--qFA4YdvGW7"
      },
      "source": [
        "## C-NN Feedforward <a class=\"anchor\" id=\"three-two\" name=\"three-two\"></a> ##\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-g8q85Lx0Uw"
      },
      "source": [
        "### Convolution <a class=\"anchor\" id=\"three-two-one\" name=\"three-two-one\"></a> ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGrcfDN9ksid"
      },
      "source": [
        "class Conv:\r\n",
        "  #Convolutional Layer Class\r\n",
        "\r\n",
        "  def __init__(self, dim, filterNum):\r\n",
        "    #dim - length of one side of conv filter (e.g. 3x3, dim=3)\r\n",
        "    #filterNum - determines how many convolution filter layers will be used\r\n",
        "    #filters - numpy arr of filters initialized with random normal distribution values\r\n",
        "    #Note: Dividing by 9 implements Xavier initialization\r\n",
        "\r\n",
        "    self.dim = dim\r\n",
        "    self.filterNum = filterNum\r\n",
        "    self.filters = np.random.randn(filterNum, dim, dim) / 9\r\n",
        "\r\n",
        "  def regionGenerator(self, image):\r\n",
        "    \"\"\"\r\n",
        "    Input: An image of mxn\r\n",
        "    Outpuut: 2d numpy arrays with yield\r\n",
        "    Functionality: Generates all possible dimxdim image regions using valid padding.\r\n",
        "    Note: Yield works better for the generator than returning a large list at once\r\n",
        "    \"\"\"\r\n",
        "    m,n = image.shape\r\n",
        "\r\n",
        "    for i in range(m - 2):\r\n",
        "      for j in range(n - 2):\r\n",
        "        region = image[i:(i + self.dim), j:(j + self.dim)]\r\n",
        "        #Yielding (rather than returning) a location with dimxdim, with associated i,j\r\n",
        "        yield region, i, j\r\n",
        "\r\n",
        "  def forward(self,input):\r\n",
        "    \"\"\"\r\n",
        "    Input: (image)\r\n",
        "    Output:(convolution for each layerNumber convolution filter)\r\n",
        "    Functionality: Performs a forward pass of a convolution layer\r\n",
        "    \"\"\"\r\n",
        "    #shape of image\r\n",
        "    m,n = input.shape\r\n",
        "    #Blank output object of valid convolution for each filter\r\n",
        "    output = np.zeros((m - 2, n - 2, self.filterNum))\r\n",
        "\r\n",
        "    #We use our generator to iterate each region to perform the convolution\r\n",
        "    #Each region has an i,j associated with it\r\n",
        "    #np.sum takes the convolutoion for that region vs filters along axis=(1,2)\r\n",
        "    for currentRegion,i,j in self.regionGenerator(input):\r\n",
        "      output[i,j] = np.sum(currentRegion * self.filters, axis= (1,2))\r\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moNojXbhVeX3"
      },
      "source": [
        "Example of Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi_OlnrhVhAX",
        "outputId": "3ac1a0b1-dee8-4d0e-fe9c-6bd5dbc867b8"
      },
      "source": [
        "object1 = Conv(3,8)\r\n",
        "output = object1.forward(xTrain[0])\r\n",
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 26, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXfeFOwzVsu7"
      },
      "source": [
        "Demonstration of Programming Used\r\n",
        "\r\n",
        "Below it is demonstrated how the matrix multiplication and sum takes place appropirately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfXIG6E6ks5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a701537-cfed-47d4-e451-84836597e816"
      },
      "source": [
        "#Here we can see filters are constructed appropriately\r\n",
        "object2 = Conv(3,8)\r\n",
        "object2.filters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.1620258 , -0.03949712,  0.18592248],\n",
              "        [-0.00688197, -0.13220466, -0.07185183],\n",
              "        [ 0.05501568, -0.14325138, -0.05393859]],\n",
              "\n",
              "       [[ 0.13471507,  0.17440606,  0.12440023],\n",
              "        [ 0.13360631, -0.01311093,  0.07599943],\n",
              "        [-0.22280663,  0.08263787,  0.17031129]],\n",
              "\n",
              "       [[ 0.00961843, -0.08931186, -0.05837847],\n",
              "        [ 0.02978031, -0.0013962 , -0.03631192],\n",
              "        [-0.27779298,  0.13273665,  0.13168553]],\n",
              "\n",
              "       [[ 0.01496955, -0.06553535, -0.0759538 ],\n",
              "        [-0.02393561,  0.02524038,  0.15201885],\n",
              "        [ 0.16809755,  0.03827875,  0.14757435]],\n",
              "\n",
              "       [[-0.06009024, -0.09169747, -0.12797365],\n",
              "        [-0.05763668, -0.133988  ,  0.00520959],\n",
              "        [-0.07593835, -0.07040611,  0.02517824]],\n",
              "\n",
              "       [[ 0.15254578, -0.04705088, -0.14702103],\n",
              "        [ 0.00200645,  0.13341694, -0.09177518],\n",
              "        [ 0.04109489, -0.02249475, -0.06718998]],\n",
              "\n",
              "       [[-0.17804608, -0.07250985, -0.13954395],\n",
              "        [ 0.03531423,  0.13210428,  0.04742926],\n",
              "        [-0.04360202,  0.07115009,  0.12084859]],\n",
              "\n",
              "       [[-0.26627974, -0.02375579,  0.01033549],\n",
              "        [-0.15875513, -0.05562005, -0.15487613],\n",
              "        [ 0.10416784, -0.12012013, -0.03611229]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw3vpJi4hlGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c63fe98-50d0-4583-e903-f83c6646a5da"
      },
      "source": [
        "#3x3 ones matrix\r\n",
        "onesDemo = np.ones((3, 3))\r\n",
        "onesDemo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.],\n",
              "       [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9VCNxyNRlIo",
        "outputId": "ba580e86-596c-4cc3-abc4-67f7a8e45b6a"
      },
      "source": [
        "#The following is ademonstration that multiplying a mxn matrix by an array of mxn matrices iterates each\r\n",
        "#They retain the same values since element-wise and ones matrix\r\n",
        "demonstration = onesDemo * object2.filters\r\n",
        "demonstration"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.1620258 , -0.03949712,  0.18592248],\n",
              "        [-0.00688197, -0.13220466, -0.07185183],\n",
              "        [ 0.05501568, -0.14325138, -0.05393859]],\n",
              "\n",
              "       [[ 0.13471507,  0.17440606,  0.12440023],\n",
              "        [ 0.13360631, -0.01311093,  0.07599943],\n",
              "        [-0.22280663,  0.08263787,  0.17031129]],\n",
              "\n",
              "       [[ 0.00961843, -0.08931186, -0.05837847],\n",
              "        [ 0.02978031, -0.0013962 , -0.03631192],\n",
              "        [-0.27779298,  0.13273665,  0.13168553]],\n",
              "\n",
              "       [[ 0.01496955, -0.06553535, -0.0759538 ],\n",
              "        [-0.02393561,  0.02524038,  0.15201885],\n",
              "        [ 0.16809755,  0.03827875,  0.14757435]],\n",
              "\n",
              "       [[-0.06009024, -0.09169747, -0.12797365],\n",
              "        [-0.05763668, -0.133988  ,  0.00520959],\n",
              "        [-0.07593835, -0.07040611,  0.02517824]],\n",
              "\n",
              "       [[ 0.15254578, -0.04705088, -0.14702103],\n",
              "        [ 0.00200645,  0.13341694, -0.09177518],\n",
              "        [ 0.04109489, -0.02249475, -0.06718998]],\n",
              "\n",
              "       [[-0.17804608, -0.07250985, -0.13954395],\n",
              "        [ 0.03531423,  0.13210428,  0.04742926],\n",
              "        [-0.04360202,  0.07115009,  0.12084859]],\n",
              "\n",
              "       [[-0.26627974, -0.02375579,  0.01033549],\n",
              "        [-0.15875513, -0.05562005, -0.15487613],\n",
              "        [ 0.10416784, -0.12012013, -0.03611229]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWKg4bIZTcmR",
        "outputId": "db57a4fd-ea6a-45da-ae88-96c1b7457547"
      },
      "source": [
        "demo1 = np.sum(onesDemo * object1.filters, axis=(0)) #Sums each of the matrices...\r\n",
        "demo2 = np.sum(onesDemo * object1.filters, axis=(1)) #Sums each col for each matrix\r\n",
        "demo3 = np.sum(onesDemo * object1.filters, axis=(2)) #Sums each row for each matrix\r\n",
        "demo4 = np.sum(onesDemo * object1.filters, axis=(1,2)) #Takes col and row sum for each matrix\r\n",
        "\r\n",
        "#This may seem confusing, but it's actually really simple.\r\n",
        "#We're asking for the max ACROSS the row and column axis, only, for each.\r\n",
        "print(demo1)\r\n",
        "print(demo2)\r\n",
        "print(demo3) \r\n",
        "print(demo4) #Yes! A sum for each matrix 1x8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.48418365  0.22823476  0.20851229]\n",
            " [ 0.05070577 -0.38035465  0.41181257]\n",
            " [ 0.37919693 -0.24723711 -0.33250606]]\n",
            "[[-0.20623554  0.09516286 -0.01933834]\n",
            " [-0.02108242 -0.13040184  0.22752261]\n",
            " [ 0.11757771 -0.37927459 -0.03802164]\n",
            " [ 0.10716064 -0.06063794  0.10955082]\n",
            " [-0.12847017 -0.09630738 -0.25285927]\n",
            " [-0.05512939  0.11672198 -0.06321427]\n",
            " [ 0.07913879  0.19505107  0.24843329]\n",
            " [ 0.05275943 -0.13967115  0.07574562]]\n",
            "[[-0.05013998  0.11177847 -0.19204951]\n",
            " [-0.11005347  0.04345985  0.14263197]\n",
            " [-0.14087143 -0.22988503  0.07103793]\n",
            " [ 0.07677365  0.07825759  0.00104227]\n",
            " [ 0.05710694 -0.15913341 -0.37561035]\n",
            " [-0.12349455  0.15754881 -0.03567594]\n",
            " [ 0.20326116  0.21644847  0.10291352]\n",
            " [ 0.03998108 -0.13631106  0.08516388]]\n",
            "[-0.13041102  0.07603835 -0.29971853  0.15607351 -0.47763682 -0.00162168\n",
            "  0.52262315 -0.0111661 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7yuPdJmhnRq"
      },
      "source": [
        "### Maxpool Class <a class=\"anchor\" id=\"three-two-two\" name=\"three-two-two\"></a> ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_pAfqH1XODs"
      },
      "source": [
        "Maxpool works nearly the same as convolution, except we take the max with no overlap instead.\r\n",
        "\r\n",
        "Note that we use axis(0,1) here to sum the row and column but not 2 (which would be summing across the filters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omouz6mShlI-"
      },
      "source": [
        "class MaxPool:\r\n",
        "  #Maxpool Class \r\n",
        "  #NOTE: We are restricted to a 2x2 maxpool for now\r\n",
        "  def __init__(self, dim):\r\n",
        "    #dim - length of one side of maxpool filter (e.g. 2x2, dim=2)\r\n",
        "    #Note: Maxpool does not overlap regions like convolution class\r\n",
        "\r\n",
        "    self.dim = dim\r\n",
        "\r\n",
        "  def regionGenerator(self,image):\r\n",
        "    m, n, _ = image.shape\r\n",
        "    m2 = m // 2\r\n",
        "    n2 = n // 2\r\n",
        "\r\n",
        "    for i in range(m2):\r\n",
        "      for j in range(n2):\r\n",
        "        region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\r\n",
        "        yield region, i, j\r\n",
        "          \r\n",
        "\r\n",
        "  def forward(self, input):\r\n",
        "    \"\"\"\r\n",
        "    Input: (matrix input)\r\n",
        "    Output: 3d matrix array of dim(m/2,n/2,filterNum)\r\n",
        "    Functionality: performs maxpool on input image for each filter\r\n",
        "    \"\"\"\r\n",
        "      \r\n",
        "    #Shape of matrix for each filter (filters make 3d)\r\n",
        "    m, n, filterNum = input.shape\r\n",
        "    #Empty output object for each filter\r\n",
        "    output = np.zeros((m // 2, n // 2, filterNum))\r\n",
        "\r\n",
        "    #Iterating across each region and finding max\r\n",
        "    for region, i, j in self.regionGenerator(input):\r\n",
        "      output[i, j] = np.amax(region, axis=(0, 1))\r\n",
        "        \r\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2ySdVhtjJu8"
      },
      "source": [
        "Example of MaxPool Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwgilHMkWUB3"
      },
      "source": [
        "conv = Conv(3,8)\r\n",
        "pool = MaxPool(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_Sq9NoJWUEX",
        "outputId": "232bde57-bc40-4907-a73c-fa91340b3bb8"
      },
      "source": [
        "output = conv.forward(xTrain[0])\r\n",
        "output = pool.forward(output)\r\n",
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13, 13, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7gh0iVUjFCF"
      },
      "source": [
        "### Softmax Class <a class=\"anchor\" id=\"three-two-three\" name=\"three-two-three\"></a> ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbo1toqMkIEy"
      },
      "source": [
        "Softmax converts a value distribution to a probability distribution. Taking the max of such will be the activation that allows for classification.\r\n",
        "\r\n",
        "Softmax Formula:\r\n",
        " $$\\frac{e^{x_i}}{\\sum_{i=0}^{i=n} e^{x_i}} \\text{ for } x_0...x_n$$\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B7pcliso9U2"
      },
      "source": [
        "I considered modifying Zhou's method to fit a natural Ax=b form. However, the advantage of not doing this is that the weights and bias arrays are row arrays. This makes indexing straight forward, as we can avoid using column and row vectors, and instead stay with simple array indexing. Computationally these should be roughly the same, the only difference being that if we wish to preserve column vectors, we would need some additional indexing. My consideration was simply to use $(xA=b)^{T}$ = $A^Tx^T = b^T$.\r\n",
        "\r\n",
        "For activation, we want to represent each of our features as a (weight*feature), weighting those features, compute a value corresponding to each digit 0...9, with some added bias. I will represent these as weights $\\omega_{0...n}$ and bias $\\beta_c$, for features $x_{0...n}$, for each digit class c.\r\n",
        "\r\n",
        "Note that for n features, we actually index 0 to n-1, not n, in python. Also note that it is better to sum our bias after, rather than to matrix multiply, because then we can keep our bias separate as an attribute of the class (without concatonation or pre-allocation of matrix A).\r\n",
        "\r\n",
        "Formula for c $\\in$ {0,1,...,9}:\r\n",
        "$$(\\omega_0x_0)+(\\omega_1x_1)+...+(\\omega_nx_n) + \\beta_c= d_c + \\beta_c = \\text{DigitValue}_{c}$$\r\n",
        "\r\n",
        "Represented as a linear algebraic system of 10 equations:\r\n",
        "\r\n",
        "Zhou's Method:\r\n",
        "\\begin{equation*}\r\n",
        "\r\n",
        "\\begin{bmatrix}\r\n",
        "\\omega_0  &\\omega_0  & \\cdots & \\omega_n  \r\n",
        "\\end{bmatrix}\r\n",
        "\r\n",
        "\\begin{bmatrix} \r\n",
        "x_{0,0} & x_{0,1} & \\cdots & x_{0,9} \\\\ \r\n",
        "x_{1,0} & x_{1,1} & \\cdots & x_{1,9}\\\\\r\n",
        "\\vdots & \\vdots & \\ddots \\\\ \r\n",
        "x_{n,0} & x_{9,1} & & x_{n,9}\r\n",
        "\\end{bmatrix}\r\n",
        "=\r\n",
        "\\begin{bmatrix}\r\n",
        "d_0 + \\beta_0  &d_1 +\\beta_1  & \\cdots & d_9+\\beta_9 \r\n",
        "\\end{bmatrix}\r\n",
        "\r\n",
        "\\end{equation*}\r\n",
        "\r\n",
        "Alternative Method:\r\n",
        "\\begin{equation*}\r\n",
        "\r\n",
        "\\begin{bmatrix} \r\n",
        "x_{0,0} & x_{0,1} & \\cdots & x_{0,n} \\\\ \r\n",
        "x_{1,0} & x_{1,1} & \\cdots & x_{1,n}\\\\\r\n",
        "\\vdots & \\vdots & \\ddots \\\\ \r\n",
        "x_{9,0} & x_{9,1} & & x_{9,n}\r\n",
        "\\end{bmatrix}\r\n",
        "\r\n",
        "\\begin{bmatrix}\r\n",
        "\\omega_0 \\\\ \r\n",
        "\\omega_1 \\\\\r\n",
        "\\vdots \\\\ \r\n",
        "\\omega_n \r\n",
        "\\end{bmatrix}\r\n",
        "\r\n",
        "=\r\n",
        "\r\n",
        "\\begin{bmatrix}\r\n",
        "d_0  \\\\ \r\n",
        "d_1  \\\\\r\n",
        "\\vdots \\\\ \r\n",
        "d_9\r\n",
        "\\end{bmatrix}\r\n",
        "+\r\n",
        "\\begin{bmatrix}\r\n",
        "\\beta_0 \\\\ \r\n",
        "\\beta_1 \\\\\r\n",
        "\\vdots \\\\ \r\n",
        "\\beta_9\r\n",
        "\\end{bmatrix}\r\n",
        "=\r\n",
        "\\begin{bmatrix}\r\n",
        "\\vdots \\\\ \r\n",
        "t_c \\\\ \r\n",
        "\\vdots\r\n",
        "\\end{bmatrix}\r\n",
        "\r\n",
        "\\end{equation*}\r\n",
        "\\\r\n",
        "Ultimitely I settled on Zhou's method because the indexing is so natural, although the alternative is the more familiar to me.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqliQB-uhlLR"
      },
      "source": [
        "\r\n",
        "class Softmax:\r\n",
        "  # A standard fully-connected layer with softmax activation.\r\n",
        "\r\n",
        "  def __init__(self, inputLen, nodes):\r\n",
        "    # inputLen - number of features m*n*k along m,n,k dimensions\r\n",
        "    # nodes - number of desired nodes\r\n",
        "    # weights - \r\n",
        "    # Note: We divide by inputLen to reduce the variance of our initial values\r\n",
        "\r\n",
        "    #np.random.seed(0)\r\n",
        "\r\n",
        "    self.weights = np.random.randn(inputLen, nodes) / inputLen\r\n",
        "    self.biases = np.zeros(nodes)\r\n",
        "\r\n",
        "  def computeSoftmax(self, valArr):\r\n",
        "    #Encapsulating the formal definition of softmax\r\n",
        "\r\n",
        "    expArr = np.exp(valArr)\r\n",
        "    return expArr / (np.sum(expArr, axis=0))\r\n",
        "\r\n",
        "  def forward(self, input):\r\n",
        "    \"\"\"\r\n",
        "    Input: Flattening allows for any input\r\n",
        "    Output: 1d array of respective probability distribution\r\n",
        "    Functionality: Computes fully connected softmax distribution with input array\r\n",
        "    \"\"\"\r\n",
        "    #Flattens the input into 1d array\r\n",
        "    input = input.flatten()\r\n",
        "\r\n",
        "    #Calculating values for each class c\r\n",
        "    totals = np.dot(input, self.weights) + self.biases\r\n",
        "\r\n",
        "    #Computing and returning probability distribution\r\n",
        "    return self.computeSoftmax(totals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GmUA5JdPf5d"
      },
      "source": [
        "Example of Softmax Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgzNkEKescjk",
        "outputId": "0f60c6fa-892a-4735-c3c3-1e280ff18d09"
      },
      "source": [
        "output = conv.forward(xTrain[0])\r\n",
        "output = pool.forward(output)\r\n",
        "softmax = Softmax(13 * 13 * 8, 10)\r\n",
        "out = softmax.forward(output)\r\n",
        "print(out)\r\n",
        "print(np.sum(out))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.06330705 0.11898444 0.13886223 0.02231434 0.01060356 0.15252899\n",
            " 0.09613176 0.19998856 0.14214247 0.0551366 ]\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd3b7oUiPlb0"
      },
      "source": [
        "### Cross-Entropy Loss <a class=\"anchor\" id=\"three-two-four\" name=\"three-two-four\"></a> ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D3xPEJ4VqVa"
      },
      "source": [
        "The cross-entropy loss function is commonly used for classification. Loss is calculated as a measure of he probability for a particular class c among a distribution (as was attained from the softmax function, for example).\r\n",
        "\r\n",
        "Naturally, being a loss function, we want to minimize the loss error.\r\n",
        "\r\n",
        "$$L = -\\ln(p_c)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHrACxjYGVri"
      },
      "source": [
        "def crossEntropyLoss(pc):\r\n",
        "  \"\"\"\r\n",
        "  Input: pc, probability for label c\r\n",
        "  Output: cross entropy loss\r\n",
        "  Functionality: Calculates cross entropy loss\r\n",
        "  \"\"\"\r\n",
        "  return (-np.log(pc))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzSX-32WGVt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438ba98a-fa25-41db-97e5-0ca79b7abb68"
      },
      "source": [
        "out[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1189844425733209"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMfjezf6GVwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1e5177-be5f-41cd-a417-cfcecb9686b6"
      },
      "source": [
        "crossEntropyLoss(out[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.128762529095106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSUEc7KigAsk"
      },
      "source": [
        "### Feedforward Method and Prediction <a class=\"anchor\" id=\"three-two-five\" name=\"three-two-five\"></a> ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILRKJm97rdKl"
      },
      "source": [
        "Feedforward thus far"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3yQE0aWw8fE"
      },
      "source": [
        "conv = Conv(3,8)\r\n",
        "pool = MaxPool(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZJtogaTGVyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ef78e7-542a-4117-d1f7-02707c306d3a"
      },
      "source": [
        "output = conv.forward(xTrain[0])\r\n",
        "output = pool.forward(output)\r\n",
        "softmax = Softmax(13 * 13 * 8, 10)\r\n",
        "out = softmax.forward(output)\r\n",
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08599052, 0.08423136, 0.21316414, 0.04457939, 0.25236947,\n",
              "       0.05047417, 0.02057091, 0.10155226, 0.11638111, 0.03068667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vr-puD5XWx7"
      },
      "source": [
        "Zhou implementation\r\n",
        "\r\n",
        "We are interested in taking the test images and labels, and observing loss and accuracy for every 100. Noticibly, accuracy is roughly 10%, which is what we'd expect with a 1/10 chance of randomly guessing the correct digit. \r\n",
        "\r\n",
        "Once training occurs, we can start to see improvements as Gradient descents updates our weights as according to our partial derivative gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtIbQf0kGV0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df3799f-d131-4695-ddd1-731d07531fee"
      },
      "source": [
        "def forward(image, label):\r\n",
        "  '''\r\n",
        "  Completes a forward pass of the CNN and calculates the accuracy and\r\n",
        "  cross-entropy loss.\r\n",
        "  - image is a 2d numpy array\r\n",
        "  - label is a digit\r\n",
        "  '''\r\n",
        "  # We transform the image from [0, 255] to [-0.5, 0.5] to make it easier\r\n",
        "  # to work with. This is standard practice.\r\n",
        "  out = conv.forward((image / 255) - 0.5)\r\n",
        "  out = pool.forward(out)\r\n",
        "  out = softmax.forward(out)\r\n",
        "\r\n",
        "  # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\r\n",
        "  loss = -np.log(out[label])\r\n",
        "  acc = 1 if np.argmax(out) == label else 0\r\n",
        "\r\n",
        "  return out, loss, acc\r\n",
        "\r\n",
        "print('MNIST CNN initialized!')\r\n",
        "\r\n",
        "loss = 0\r\n",
        "num_correct = 0\r\n",
        "for i, (im, label) in enumerate(zip(xTest[0:400], yTest[0:400])):\r\n",
        "  # Do a forward pass.\r\n",
        "  _, l, acc = forward(im, label)\r\n",
        "  loss += l\r\n",
        "  num_correct += acc\r\n",
        "\r\n",
        "  # Print stats every 100 steps.\r\n",
        "  if i % 100 == 99:\r\n",
        "    print(\r\n",
        "      '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\r\n",
        "      (i + 1, loss / 100, num_correct)\r\n",
        "    )\r\n",
        "    loss = 0\r\n",
        "    num_correct = 0\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST CNN initialized!\n",
            "[Step 100] Past 100 steps: Average Loss 2.302 | Accuracy: 9%\n",
            "[Step 200] Past 100 steps: Average Loss 2.302 | Accuracy: 13%\n",
            "[Step 300] Past 100 steps: Average Loss 2.302 | Accuracy: 10%\n",
            "[Step 400] Past 100 steps: Average Loss 2.303 | Accuracy: 8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSFBFeRMrzR2"
      },
      "source": [
        "Alternative Identical Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjl7WQq6Z6JF"
      },
      "source": [
        "Object Instantiation and Feedforward Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5w0wjxOZ9R4"
      },
      "source": [
        "#Instantiation\r\n",
        "conv = Conv(3,8)\r\n",
        "pool = MaxPool(2)\r\n",
        "softmax = Softmax(13 * 13 * 8, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nl3EX2vZ3e-"
      },
      "source": [
        "Alternative Feedforward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvVuX4t1eGzR"
      },
      "source": [
        "def feedforwardModify(image,label):\r\n",
        "  \"\"\"\r\n",
        "  Input: An image and label\r\n",
        "  Output: probability distribution,loss,accuracy\r\n",
        "  Functionality: Conducts forward pass predicting an image \r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  #converts to [-0.5,0.5]\r\n",
        "  #feedforward through convolution,pool,activation,softmax\r\n",
        "  output = conv.forward((image / 255) - 0.5)\r\n",
        "  output = pool.forward(output)\r\n",
        "  output = softmax.forward(output)\r\n",
        "\r\n",
        "  loss = crossEntropyLoss(output[label])\r\n",
        "\r\n",
        "  if(np.argmax(output) == label):\r\n",
        "    acc = 1\r\n",
        "  else:\r\n",
        "    acc = 0\r\n",
        "\r\n",
        "  return output, loss, acc\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEEeJ0LjeG1m",
        "outputId": "56dcd8b5-83ef-47a7-c12b-56a73506a358"
      },
      "source": [
        "\r\n",
        "print('MNIST CNN initialized!')\r\n",
        "loss = 0\r\n",
        "num_correct = 0\r\n",
        "for i, (im, label) in enumerate(zip(xTest[0:400], yTest[0:400])):\r\n",
        "  # Do a forward pass.\r\n",
        "  _, l, acc = feedforwardModify(im, label)\r\n",
        "  loss += l\r\n",
        "  num_correct += acc\r\n",
        "\r\n",
        "  # Print stats every 100 steps.\r\n",
        "  if i % 100 == 99:\r\n",
        "    print(\r\n",
        "      '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\r\n",
        "      (i + 1, loss / 100, num_correct)\r\n",
        "    )\r\n",
        "    loss = 0\r\n",
        "    num_correct = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST CNN initialized!\n",
            "[Step 100] Past 100 steps: Average Loss 2.302 | Accuracy: 9%\n",
            "[Step 200] Past 100 steps: Average Loss 2.302 | Accuracy: 13%\n",
            "[Step 300] Past 100 steps: Average Loss 2.302 | Accuracy: 10%\n",
            "[Step 400] Past 100 steps: Average Loss 2.303 | Accuracy: 8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yL2Gd-3f66J"
      },
      "source": [
        "Feedforward without label in feedforward function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAeL1mnSgzTV"
      },
      "source": [
        "def feedforward(image):\r\n",
        "  \"\"\"\r\n",
        "  Input: An image\r\n",
        "  Output: A probability distribution for a given test image\r\n",
        "  Functionality: Conducts forward pass predicting an image\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  #converts to [-0.5,0.5]\r\n",
        "  #feedforward through convolution,pool,activation,softmax\r\n",
        "  output = conv.forward((image / 255) - 0.5)\r\n",
        "  output = pool.forward(output)\r\n",
        "  output = softmax.forward(output)\r\n",
        "\r\n",
        "  return output\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZD6W3mTgzVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19149395-0802-4532-acab-8fd481bb9f01"
      },
      "source": [
        "feedforward(xTest[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10051936, 0.10015951, 0.09934844, 0.10009936, 0.10007277,\n",
              "       0.09993042, 0.09971149, 0.10028407, 0.09955879, 0.10031578])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxxTrDuXgzXz"
      },
      "source": [
        "# Loss and accuracy specific to the particular digit, rather than each 100\r\n",
        "\r\n",
        "loss = np.zeros(len(xTest[0:500]))\r\n",
        "predictedValues = np.zeros(len(xTest[0:500]))\r\n",
        "\r\n",
        "for i, (im, label) in enumerate(zip(xTest[0:500], yTest[0:500])):\r\n",
        "\r\n",
        "  #Feedforward a single image\r\n",
        "  probDist = feedforward(xTest[i])\r\n",
        "\r\n",
        "  #Predicted digit is the argmax of the prob distribution\r\n",
        "  predictedDigit = np.argmax(probDist)\r\n",
        "\r\n",
        "  #Storing loss for index i\r\n",
        "  loss[i] = crossEntropyLoss(out[label])\r\n",
        "\r\n",
        "  #Adding the digit into a prediction array for a confusion matrix\r\n",
        "  predictedValues[i] = predictedDigit\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrQqacAtgzZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33e3929-bab4-474b-a857-36446fdeb393"
      },
      "source": [
        "#Approximately the same overall mean loss\r\n",
        "loss.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.5441826909785332"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUrqDxY_GV5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa51090-2643-48a0-8b6d-271af1cc10c2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "confusionMat = confusion_matrix(yTest[0:500], predictedValues)\r\n",
        "confusionMat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 13,  0, 12,  6,  0,  2,  6,  0,  3],\n",
              "       [ 3,  5,  0,  0,  9,  0,  0,  6,  0, 44],\n",
              "       [ 2, 11,  0,  1,  4,  0,  0,  6,  0, 31],\n",
              "       [ 2, 16,  0,  0, 11,  0,  1,  2,  0, 13],\n",
              "       [ 2,  3,  0,  1, 21,  0,  0,  9,  0, 19],\n",
              "       [ 2, 14,  0,  5, 16,  0,  0, 10,  0,  3],\n",
              "       [ 0,  3,  0,  4, 17,  0,  0, 14,  0,  5],\n",
              "       [14,  1,  0,  0,  8,  0,  0,  1,  0, 25],\n",
              "       [ 0,  4,  0,  0, 12,  0,  0, 17,  0,  7],\n",
              "       [ 2,  2,  0,  0, 22,  0,  0,  4,  0, 24]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igFNrtMpq_9R",
        "outputId": "c64d52a8-5969-45ed-e918-6e1b6d43350b"
      },
      "source": [
        "#Also roughly 10%\r\n",
        "confusionMat.trace() / np.sum(confusionMat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUplVr82tUqS"
      },
      "source": [
        "## Back Propagation and Training <a class=\"anchor\" id=\"three-three\" name=\"three-three\"></a>##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obq101yiy4VL"
      },
      "source": [
        "Now that we have a feedforward process, we need to be able to train our feedforward with back-propagation.\r\n",
        "\r\n",
        "To do this, we will cache data for each layer. Then we will update our loss gradient as we pass through each layer, and as we update for each image.\r\n",
        "\r\n",
        "Recall loss was defined using cross-entropy loss: $-\\ln(p_c)$. As such, the derivative will be \r\n",
        "\r\n",
        "0 if i $\\neq c$\r\n",
        "\r\n",
        "$-\\frac{1}{p_i}$ if i $=c$\r\n",
        "\r\n",
        "There is quite some more calculus involved for calculating and updating the gradient. I will skip this for now, as Zhou covered it very well. Since it seems mostly definitional, I will copy his implementation, as far as I understand it.\r\n",
        "\r\n",
        "In particular, we have a generalized gradient, but this general gradient has no way to be updated appropriately within our code. As such, we need to continue to derive until we can calculate gradients relative to what is in our code, namely weights, x pixel 'totals', and a bias for each class.\r\n",
        "\r\n",
        "Thus, we calculate a entropy loss gradient. Then calculate a softmax gradient. Then from this we can find gradients in the former regards, and update those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y63jLbG7AnTA"
      },
      "source": [
        "#Overall Idea:\r\n",
        "\r\n",
        "# Feed forward\r\n",
        "#out = conv.forward((image / 255) - 0.5)\r\n",
        "#out = pool.forward(out)\r\n",
        "#out = softmax.forward(out)\r\n",
        "\r\n",
        "# Calculate initial gradient\r\n",
        "#gradient = np.zeros(10)\r\n",
        "#gradient[label] = -1 / out[label]\r\n",
        "\r\n",
        "# Backprop\r\n",
        "#gradient = softmax.backprop(gradient)\r\n",
        "#gradient = pool.backprop(gradient)\r\n",
        "#gradient = conv.backprop(gradient)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we6xaIfUBf2J",
        "outputId": "c35d6989-e297-4143-d279-676e47b786d3"
      },
      "source": [
        "# Feed forward\r\n",
        "out = conv.forward((xTest[0] / 255) - 0.5)\r\n",
        "out = pool.forward(out)\r\n",
        "out = softmax.forward(out)\r\n",
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10051936, 0.10015951, 0.09934844, 0.10009936, 0.10007277,\n",
              "       0.09993042, 0.09971149, 0.10028407, 0.09955879, 0.10031578])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC-0UMdqB8dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4dd063b-ddae-4a0f-b9d8-e508b6f69d93"
      },
      "source": [
        "label = np.argmax(out)\r\n",
        "label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKI2eWjuB6OF",
        "outputId": "29357ed2-8e26-4832-b74b-06eec9fbaf15"
      },
      "source": [
        "#Thus we add the computed derivative at the location of the label, and 0 otherwise\r\n",
        "gradient = np.zeros(10)\r\n",
        "gradient[label] = -1 / out[label]\r\n",
        "gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-9.94833281,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLRITkDWxbOu"
      },
      "source": [
        "### Softmax Back Propagation <a class=\"anchor\" id=\"three-three-one\" name=\"three-three-one\"></a> ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGRd0qQK8FKP"
      },
      "source": [
        "Zhou implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYDKIS918E89"
      },
      "source": [
        "class Softmax:\r\n",
        "\r\n",
        "  def __init__(self, inputLen, nodes):\r\n",
        "\r\n",
        "    #Used for testing the method, but not used in practice\r\n",
        "    np.random.seed(0)\r\n",
        "\r\n",
        "    self.weights = np.random.randn(inputLen, nodes) / inputLen\r\n",
        "    self.biases = np.zeros(nodes)\r\n",
        "\r\n",
        "  def forward(self, input):\r\n",
        "    '''\r\n",
        "    Performs a forward pass of the softmax layer using the given input.\r\n",
        "    Returns a 1d numpy array containing the respective probability values.\r\n",
        "    - input can be any array with any dimensions.\r\n",
        "    '''\r\n",
        "    self.last_input_shape = input.shape\r\n",
        "\r\n",
        "    input = input.flatten()\r\n",
        "    self.last_input = input\r\n",
        "\r\n",
        "    input_len, nodes = self.weights.shape\r\n",
        "\r\n",
        "    totals = np.dot(input, self.weights) + self.biases\r\n",
        "    self.last_totals = totals\r\n",
        "\r\n",
        "    exp = np.exp(totals)\r\n",
        "    return exp / np.sum(exp, axis=0)\r\n",
        "\r\n",
        "  def backprop(self, d_L_d_out, learn_rate):\r\n",
        "    '''\r\n",
        "    Performs a backward pass of the softmax layer.\r\n",
        "    Returns the loss gradient for this layer's inputs.\r\n",
        "    - d_L_d_out is the loss gradient for this layer's outputs.\r\n",
        "    '''\r\n",
        "    #Simply used to test if indeed we arive at the same answer\r\n",
        "    global d_out_d_t\r\n",
        "\r\n",
        "    # We know only 1 element of d_L_d_out will be nonzero\r\n",
        "    for i, gradient in enumerate(d_L_d_out):\r\n",
        "      if gradient == 0:\r\n",
        "        continue\r\n",
        "\r\n",
        "      # e^totals\r\n",
        "      t_exp = np.exp(self.last_totals)\r\n",
        "\r\n",
        "      # Sum of all e^totals\r\n",
        "      S = np.sum(t_exp)\r\n",
        "\r\n",
        "      # Gradients of out[i] against totals\r\n",
        "      d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\r\n",
        "      d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\r\n",
        "\r\n",
        "      # Gradients of loss against totals\r\n",
        "      d_L_d_t = gradient * d_out_d_t\r\n",
        "\r\n",
        "      # Gradients of totals against weights/biases/input\r\n",
        "      d_t_d_w = self.last_input      \r\n",
        "      d_t_d_b = 1      \r\n",
        "      d_t_d_inputs = self.weights\r\n",
        "      # Gradients of loss against totals\r\n",
        "      d_L_d_t = gradient * d_out_d_t\r\n",
        "      # Gradients of loss against weights/biases/input      \r\n",
        "      d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]      \r\n",
        "      d_L_d_b = d_L_d_t * d_t_d_b      \r\n",
        "      d_L_d_inputs = d_t_d_inputs @ d_L_d_t\r\n",
        "\r\n",
        "      # Update weights / biases      \r\n",
        "      self.weights -= learn_rate * d_L_d_w      \r\n",
        "      self.biases -= learn_rate * d_L_d_b      \r\n",
        "      return d_L_d_inputs.reshape(self.last_input_shape)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-PUeAiP9tnC"
      },
      "source": [
        "Testing out the Zhou implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kgAUfky8JBa"
      },
      "source": [
        "#Instantiation of conv and pool\r\n",
        "conv = Conv(3,8)\r\n",
        "pool = MaxPool(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGKexehW8JDz"
      },
      "source": [
        "#Instantiation of softmax \r\n",
        "softmax = Softmax(13 * 13 * 8, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lwVucd78JGB",
        "outputId": "971c8f11-2d8a-40b0-e6eb-9d47bd188a9f"
      },
      "source": [
        "# Feedforward\r\n",
        "out = conv.forward((xTest[0] / 255) - 0.5)\r\n",
        "out = pool.forward(out)\r\n",
        "out = softmax.forward(out)\r\n",
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09956664, 0.10051692, 0.09956403, 0.09976503, 0.0999775 ,\n",
              "       0.09986324, 0.10034217, 0.10006443, 0.10011014, 0.10022991])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAeE_sge8JIW",
        "outputId": "08dbe87e-c823-4bb5-e23c-aa15474ed949"
      },
      "source": [
        "label = np.argmax(out)\r\n",
        "\r\n",
        "#Thus we add the computed derivative at the location of the label, and 0 otherwise\r\n",
        "gradient = np.zeros(10)\r\n",
        "gradient[label] = -1 / out[label]\r\n",
        "gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        , -9.94857408,  0.        ,  0.        ,  0.        ,\n",
              "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1boNZiS8JKs"
      },
      "source": [
        "#Carrying out backpropagation\r\n",
        "softmax.backprop(gradient)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQbi89vj8JM9",
        "outputId": "c8f3c768-632e-4cc5-ad7d-a23065e17d46"
      },
      "source": [
        "#Let's see if its the same with my implementation\r\n",
        "d_out_d_t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01000813,  0.09041327, -0.01000787, -0.01002807, -0.01004943,\n",
              "       -0.01003795, -0.01008609, -0.01005817, -0.01006276, -0.0100748 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npRr_kLS8JkY"
      },
      "source": [
        "My implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3hCvFt8T5e-"
      },
      "source": [
        "This implementation is mostly the same with some minor changes to how we find the nonzero, and some naming.\r\n",
        "\r\n",
        "However, If I decide to change the dimensions of the prior implementation of softmax, to my matrix form, then I would edit this as well. Doing so would make the matrix multiplications of $\\frac{d_L}{d_t} \\cdot \\frac{d_t}{d_{\\text{wanted}}}$ more straightforward left multiplications, but result in column vectors when storing our attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwZMfWDUrACB"
      },
      "source": [
        "class Softmax:\r\n",
        "  # A standard fully-connected layer with softmax activation.\r\n",
        "\r\n",
        "  def __init__(self, inputLen, nodes):\r\n",
        "    # inputLen - number of features m*n*k along m,n,k dimensions\r\n",
        "    # nodes - number of desired nodes\r\n",
        "    # weights - weights multiplied by x values\r\n",
        "    # biases biases added to each tc = sum(xc*wc)\r\n",
        "    # Note: We divide by inputLen to reduce the variance of our initial values\r\n",
        "\r\n",
        "    #Used for testing the method, but not used in practice\r\n",
        "    #np.random.seed(0)\r\n",
        "\r\n",
        "    self.weights = np.random.randn(inputLen, nodes) / inputLen\r\n",
        "    self.biases = np.zeros(nodes)\r\n",
        "\r\n",
        "  def computeSoftmax(self, valArr):\r\n",
        "    #Encapsulating the formal definition of softmax\r\n",
        "\r\n",
        "    expArr = np.exp(valArr)\r\n",
        "    return expArr / (np.sum(expArr, axis=0))\r\n",
        "\r\n",
        "  def forward(self, input):\r\n",
        "    \"\"\"\r\n",
        "    Input: Flattening allows for any input\r\n",
        "    Output: 1d array of respective probability distribution\r\n",
        "    Functionality: Computes fully connected softmax distribution with input array\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Stores original shape\r\n",
        "    self.orginalShape = input.shape\r\n",
        "\r\n",
        "    # Flattens the input into 1d array\r\n",
        "    input = input.flatten()\r\n",
        "\r\n",
        "    # Stores flat input\r\n",
        "    self.flatInput = input\r\n",
        "\r\n",
        "    # Calculating values for each class c\r\n",
        "    totals = np.dot(input, self.weights) + self.biases\r\n",
        "\r\n",
        "    # Stores activation sum of (weights*input)+bias_c\r\n",
        "    self.flatTotals = totals\r\n",
        "\r\n",
        "    # Computing and returning probability distribution\r\n",
        "    return self.computeSoftmax(totals)\r\n",
        "\r\n",
        "  def backprop(self, d_L_d_out,learn_rate):\r\n",
        "    \"\"\"\r\n",
        "    Input: d_L_d_out; loss gradient at softmax\r\n",
        "    Output: Updates loss gradient.\r\n",
        "    Functionality: Backwards propagation for softmax layer\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # Instead of for loop, extracting only nonzero\r\n",
        "    i = np.nonzero(d_L_d_out)\r\n",
        "    gradient = d_L_d_out[i]\r\n",
        "\r\n",
        "    # Softmax calculations\r\n",
        "    t_exp = np.exp(self.flatTotals)\r\n",
        "    S = np.sum(t_exp)\r\n",
        "\r\n",
        "    # Gradients of out[i] against totals\r\n",
        "    d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\r\n",
        "    d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\r\n",
        "\r\n",
        "    # Gradients of loss against totals\r\n",
        "    d_L_d_t = gradient * d_out_d_t\r\n",
        "      \r\n",
        "    # Gradients of totals against weights/biases/input\r\n",
        "    d_t_d_w = self.flatInput      \r\n",
        "    d_t_d_b = 1      \r\n",
        "    d_t_d_inputs = self.weights\r\n",
        "\r\n",
        "    # Gradients of loss against totals\r\n",
        "    d_L_d_t = gradient * d_out_d_t\r\n",
        "\r\n",
        "    # Gradients of loss against weights/biases/input \r\n",
        "    # These are what we are especially interested in    \r\n",
        "    # Note: @ is simply the matmul function (matrix multiplication)\r\n",
        "    # It took a bit of playing around to see that these indeed work\r\n",
        "    #New axis simply increases dimension, so an np.array -> vector/matrix\r\n",
        "\r\n",
        "    # Note that matrices are not commutative in multiplication\r\n",
        "    # Note the pattern of chaining partial derivatives\r\n",
        "    # Likewise, note dL/dt = dL/dout * dout/dt\r\n",
        "\r\n",
        "    # dL/dw = dL/dout*dout/dt*dt/dw= dL/dt * dt/dw = dt/dw*dL/dt \r\n",
        "    d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]    \r\n",
        "\r\n",
        "    # dL/db = dL/dt*dout/dt*dt/db = dL/dt*dt/db\r\n",
        "    d_L_d_b = d_L_d_t * d_t_d_b    \r\n",
        "\r\n",
        "    # dL/dinput = dL/dt*dout/dt*dt/dinput = dL/dt*dt/dinputs = dt/dinput * dL/dt\r\n",
        "    d_L_d_inputs = d_t_d_inputs @ d_L_d_t\r\n",
        "\r\n",
        "    # Update weights / biases with learn rate     \r\n",
        "    self.weights -= learn_rate * d_L_d_w      \r\n",
        "    self.biases -= learn_rate * d_L_d_b \r\n",
        "\r\n",
        "    return d_L_d_inputs.reshape(self.orginalShape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5LmfTSGU86A"
      },
      "source": [
        "    #Hmmmm I might actually implement a new matrix schema...\r\n",
        "    \r\n",
        "    # Because of the shape...we'd have to take the transpose of the whole...\r\n",
        "    #d_L_d_w2 = d_L_d_t[np.newaxis].T @ d_t_d_w[np.newaxis]\r\n",
        "    #d_L_d_w2 = d_L_d_w2.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8J_WkjC1oVp"
      },
      "source": [
        "Testing Our Back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij8ZzhFz5Zxb"
      },
      "source": [
        "#Instantiation of softmax \r\n",
        "softmax = Softmax(13 * 13 * 8, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PepV7msv_RTo",
        "outputId": "b643c95f-f3af-49de-f0a3-402475b8bfdb"
      },
      "source": [
        "# Feedforward\r\n",
        "out = conv.forward((xTest[0] / 255) - 0.5)\r\n",
        "out = pool.forward(out)\r\n",
        "out = softmax.forward(out)\r\n",
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09956664, 0.10051692, 0.09956403, 0.09976503, 0.0999775 ,\n",
              "       0.09986324, 0.10034217, 0.10006443, 0.10011014, 0.10022991])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFkcnTx3_RVr",
        "outputId": "504631b7-2ed4-49d6-c35b-f58595f05f21"
      },
      "source": [
        "label = np.argmax(out)\r\n",
        "\r\n",
        "#Thus we add the computed derivative at the location of the label, and 0 otherwise\r\n",
        "gradient = np.zeros(10)\r\n",
        "gradient[label] = -1 / out[label]\r\n",
        "gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        , -9.94857408,  0.        ,  0.        ,  0.        ,\n",
              "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCkf2D3R_RYK"
      },
      "source": [
        "softmax.backprop(gradient)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohRcA8Gh_RaN",
        "outputId": "4854760f-f888-4e77-d6f0-873c6a7ed93b"
      },
      "source": [
        "#Sugoi\r\n",
        "d_out_d_t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01000813,  0.09041327, -0.01000787, -0.01002807, -0.01004943,\n",
              "       -0.01003795, -0.01008609, -0.01005817, -0.01006276, -0.0100748 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jltE-RBtLRnD"
      },
      "source": [
        "The following is personal testing for matrix dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNgdYH-HLVzr"
      },
      "source": [
        "#Instantiation of softmax \r\n",
        "softmax = Softmax(13 * 13 * 8, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWrKwGISLV12",
        "outputId": "e0fb7f14-2bc2-421d-b492-07ff25737c27"
      },
      "source": [
        "# Feedforward\r\n",
        "out = conv.forward((xTest[0] / 255) - 0.5)\r\n",
        "out = pool.forward(out)\r\n",
        "out = softmax.forward(out)\r\n",
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.09956664, 0.10051692, 0.09956403, 0.09976503, 0.0999775 ,\n",
              "       0.09986324, 0.10034217, 0.10006443, 0.10011014, 0.10022991])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qftc9ZUVLV4S",
        "outputId": "c579c7bc-f83e-49d6-afe8-3086e5178b3a"
      },
      "source": [
        "label = np.argmax(out)\r\n",
        "\r\n",
        "#Thus we add the computed derivative at the location of the label, and 0 otherwise\r\n",
        "gradient = np.zeros(10)\r\n",
        "gradient[label] = -1 / out[label]\r\n",
        "gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        , -9.94857408,  0.        ,  0.        ,  0.        ,\n",
              "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2p47U3BLV6w"
      },
      "source": [
        "nextOut1 = softmax.backprop(gradient,0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXWgkbGVLV9O",
        "outputId": "b274af48-dbbe-447f-b401-e32d93b282e1"
      },
      "source": [
        "#Comparing my output with his...\r\n",
        "nextOut == nextOut1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0j1vJHGX4ku"
      },
      "source": [
        "Training with only softmax back Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epp5wcvuYcHb"
      },
      "source": [
        "#Instantiation of softmax \r\n",
        "softmax = Softmax(13 * 13 * 8, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUzq1lauU2bA",
        "outputId": "0ecc62dc-e857-425b-baef-2b8cd9f0d52a"
      },
      "source": [
        "def train(im, label, lr=.005):\r\n",
        "  '''\r\n",
        "  Completes a full training step on the given image and label.\r\n",
        "  Returns the cross-entropy loss and accuracy.\r\n",
        "  - image is a 2d numpy array\r\n",
        "  - label is a digit\r\n",
        "  - lr is the learning rate\r\n",
        "  '''\r\n",
        "  # Forward\r\n",
        "  out, loss, acc = feedforwardModify(im, label)\r\n",
        "\r\n",
        "  # Calculate initial gradient\r\n",
        "  gradient = np.zeros(10)\r\n",
        "  gradient[label] = -1 / out[label]\r\n",
        "\r\n",
        "  # Backprop\r\n",
        "  gradient = softmax.backprop(gradient, lr)\r\n",
        "  # TODO: backprop MaxPool layer\r\n",
        "  # TODO: backprop Conv layer\r\n",
        "\r\n",
        "  return loss, acc\r\n",
        "\r\n",
        "print('MNIST CNN initialized!')\r\n",
        "\r\n",
        "# Train!\r\n",
        "loss = 0\r\n",
        "num_correct = 0\r\n",
        "for i, (im, label) in enumerate(zip(xTrain[0:1000], yTrain[0:1000])):\r\n",
        "  if i % 100 == 99:\r\n",
        "    print(\r\n",
        "      '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\r\n",
        "      (i + 1, loss / 100, num_correct)\r\n",
        "    )\r\n",
        "    loss = 0\r\n",
        "    num_correct = 0\r\n",
        "\r\n",
        "  l, acc = train(im, label)\r\n",
        "  loss += l\r\n",
        "  num_correct += acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST CNN initialized!\n",
            "[Step 100] Past 100 steps: Average Loss 2.246 | Accuracy: 22%\n",
            "[Step 200] Past 100 steps: Average Loss 2.195 | Accuracy: 38%\n",
            "[Step 300] Past 100 steps: Average Loss 2.116 | Accuracy: 56%\n",
            "[Step 400] Past 100 steps: Average Loss 2.031 | Accuracy: 69%\n",
            "[Step 500] Past 100 steps: Average Loss 1.977 | Accuracy: 67%\n",
            "[Step 600] Past 100 steps: Average Loss 1.987 | Accuracy: 50%\n",
            "[Step 700] Past 100 steps: Average Loss 1.936 | Accuracy: 53%\n",
            "[Step 800] Past 100 steps: Average Loss 1.844 | Accuracy: 71%\n",
            "[Step 900] Past 100 steps: Average Loss 1.785 | Accuracy: 74%\n",
            "[Step 1000] Past 100 steps: Average Loss 1.755 | Accuracy: 70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5NSMXVKX8e7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlt5aboOX8hL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DodYDRvcX8jb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD9x7kAGX8lv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8353SexLV_n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzgODVrvLWB0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTr6lZL1LWEO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTG_z44dxlPW"
      },
      "source": [
        "### Maxpool Back Propagation <a class=\"anchor\" id=\"three-three-two\" name=\"three-three-two\"></a> ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPUcN0M3xa0a"
      },
      "source": [
        "class MaxPool:\r\n",
        "  #Maxpool Class \r\n",
        "  #NOTE: We are restricted to a 2x2 maxpool for now\r\n",
        "  def __init__(self, dim):\r\n",
        "    #dim - length of one side of maxpool filter (e.g. 2x2, dim=2)\r\n",
        "    #Note: Maxpool does not overlap regions like convolution class\r\n",
        "\r\n",
        "    self.dim = dim\r\n",
        "\r\n",
        "  def regionGenerator(self,image):\r\n",
        "    m, n, _ = image.shape\r\n",
        "    m2 = m // 2\r\n",
        "    n2 = n // 2\r\n",
        "\r\n",
        "    for i in range(m2):\r\n",
        "      for j in range(n2):\r\n",
        "        region = image[(i * 2):(i * 2 + 2), (j * 2):(j * 2 + 2)]\r\n",
        "        yield region, i, j\r\n",
        "          \r\n",
        "\r\n",
        "  def forward(self, input):\r\n",
        "    \"\"\"\r\n",
        "    Input: (matrix input)\r\n",
        "    Output: 3d matrix array of dim(m/2,n/2,filterNum)\r\n",
        "    Functionality: performs maxpool on input image for each filter\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    self.last_input = input\r\n",
        "\r\n",
        "    #Shape of matrix for each filter (filters make 3d)\r\n",
        "    m, n, filterNum = input.shape\r\n",
        "    #Empty output object for each filter\r\n",
        "    output = np.zeros((m // 2, n // 2, filterNum))\r\n",
        "\r\n",
        "    #Iterating across each region and finding max\r\n",
        "    for region, i, j in self.regionGenerator(input):\r\n",
        "      output[i, j] = np.amax(region, axis=(0, 1))\r\n",
        "        \r\n",
        "    return output\r\n",
        "\r\n",
        "  def backprop(self, d_L_d_out):\r\n",
        "    '''\r\n",
        "    Performs a backward pass of the maxpool layer.\r\n",
        "    Returns the loss gradient for this layer's inputs.\r\n",
        "    - d_L_d_out is the loss gradient for this layer's outputs.\r\n",
        "    '''\r\n",
        "    d_L_d_input = np.zeros(self.last_input.shape)\r\n",
        "\r\n",
        "    for region, i, j in self.regionGenerator(self.last_input):\r\n",
        "      h, w, f = region.shape\r\n",
        "      amax = np.amax(region, axis=(0, 1))\r\n",
        "\r\n",
        "      for i2 in range(h):\r\n",
        "        for j2 in range(w):\r\n",
        "          for f2 in range(f):\r\n",
        "            # If this pixel was the max value, copy the gradient to it.\r\n",
        "            if region[i2, j2, f2] == amax[f2]:\r\n",
        "              d_L_d_input[i * 2 + i2, j * 2 + j2, f2] = d_L_d_out[i, j, f2]\r\n",
        "\r\n",
        "    return d_L_d_input\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i1Nodo8u86A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7yq8S7gu88Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tzr-teSvrAES"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkkC5WfY3zyN"
      },
      "source": [
        "### Convolution Back Propagation <a class=\"anchor\" id=\"three-three-three\" name=\"three-three-three\"></a> ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiNDdB0D38DT"
      },
      "source": [
        "class Conv:\r\n",
        "  #Convolutional Layer Class\r\n",
        "\r\n",
        "  def __init__(self, dim, filterNum):\r\n",
        "    #dim - length of one side of conv filter (e.g. 3x3, dim=3)\r\n",
        "    #filterNum - determines how many convolution filter layers will be used\r\n",
        "    #filters - numpy arr of filters initialized with random normal distribution values\r\n",
        "    #Note: Dividing by 9 implements Xavier initialization\r\n",
        "\r\n",
        "    self.dim = dim\r\n",
        "    self.filterNum = filterNum\r\n",
        "    self.filters = np.random.randn(filterNum, dim, dim) / 9\r\n",
        "\r\n",
        "  def regionGenerator(self, image):\r\n",
        "    \"\"\"\r\n",
        "    Input: An image of mxn\r\n",
        "    Outpuut: 2d numpy arrays with yield\r\n",
        "    Functionality: Generates all possible dimxdim image regions using valid padding.\r\n",
        "    Note: Yield works better for the generator than returning a large list at once\r\n",
        "    \"\"\"\r\n",
        "    m,n = image.shape\r\n",
        "\r\n",
        "    for i in range(m - 2):\r\n",
        "      for j in range(n - 2):\r\n",
        "        region = image[i:(i + self.dim), j:(j + self.dim)]\r\n",
        "        #Yielding (rather than returning) a location with dimxdim, with associated i,j\r\n",
        "        yield region, i, j\r\n",
        "\r\n",
        "  def forward(self,input):\r\n",
        "    \"\"\"\r\n",
        "    Input: (image)\r\n",
        "    Output:(convolution for each layerNumber convolution filter)\r\n",
        "    Functionality: Performs a forward pass of a convolution layer\r\n",
        "    \"\"\"\r\n",
        "    #shape of image\r\n",
        "    m,n = input.shape\r\n",
        "    #Blank output object of valid convolution for each filter\r\n",
        "    output = np.zeros((m - 2, n - 2, self.filterNum))\r\n",
        "\r\n",
        "    #Cache input\r\n",
        "    self.last_input = input\r\n",
        "\r\n",
        "    #We use our generator to iterate each region to perform the convolution\r\n",
        "    #Each region has an i,j associated with it\r\n",
        "    #np.sum takes the convolutoion for that region vs filters along axis=(1,2)\r\n",
        "    for currentRegion,i,j in self.regionGenerator(input):\r\n",
        "      output[i,j] = np.sum(currentRegion * self.filters, axis= (1,2))\r\n",
        "    return output\r\n",
        "\r\n",
        "  def backprop(self, d_L_d_out, learn_rate):\r\n",
        "    '''\r\n",
        "    Performs a backward pass of the conv layer.\r\n",
        "    - d_L_d_out is the loss gradient for this layer's outputs.\r\n",
        "    - learn_rate is a float.\r\n",
        "    '''\r\n",
        "    d_L_d_filters = np.zeros(self.filters.shape)\r\n",
        "\r\n",
        "    for region, i, j in self.regionGenerator(self.last_input):\r\n",
        "      for f in range(self.filterNum):\r\n",
        "        d_L_d_filters[f] += d_L_d_out[i, j, f] * region\r\n",
        "\r\n",
        "    # Update filters\r\n",
        "    self.filters -= learn_rate * d_L_d_filters\r\n",
        "\r\n",
        "    #Not returning anything here since we use Conv as the first layer\r\n",
        "    #Otherwise, return the loss gradient for this layer inputs like other layers\r\n",
        "    return None\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf2KQARwLZ67"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUQ0kRoaddJv"
      },
      "source": [
        "### Training with Epochs <a class=\"anchor\" id=\"three-three-four\" name=\"three-three-four\"></a> ### "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kPL7pbTdkOc"
      },
      "source": [
        "#Instantiation of conv and pool\r\n",
        "conv = Conv(3,8)\r\n",
        "pool = MaxPool(2)\r\n",
        "softmax = Softmax(13 * 13 * 8, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqu3z72QLZ_L"
      },
      "source": [
        "def feedforwardModify(image,label):\r\n",
        "  \"\"\"\r\n",
        "  Input: An image and label\r\n",
        "  Output: probability distribution,loss,accuracy\r\n",
        "  Functionality: Conducts forward pass predicting an image \r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  #converts to [-0.5,0.5]\r\n",
        "  #feedforward through convolution,pool,activation,softmax\r\n",
        "  output = conv.forward((image / 255) - 0.5)\r\n",
        "  output = pool.forward(output)\r\n",
        "  output = softmax.forward(output)\r\n",
        "\r\n",
        "  loss = crossEntropyLoss(output[label])\r\n",
        "\r\n",
        "  if(np.argmax(output) == label):\r\n",
        "    acc = 1\r\n",
        "  else:\r\n",
        "    acc = 0\r\n",
        "\r\n",
        "  return output, loss, acc\r\n",
        "\r\n",
        "def train(im, label, lr=.005):\r\n",
        "  '''\r\n",
        "  Completes a full training step on the given image and label.\r\n",
        "  Returns the cross-entropy loss and accuracy.\r\n",
        "  - image is a 2d numpy array\r\n",
        "  - label is a digit\r\n",
        "  - lr is the learning rate\r\n",
        "  '''\r\n",
        "  # Forward\r\n",
        "  out, loss, acc = feedforwardModify(im, label)\r\n",
        "\r\n",
        "  # Calculate initial gradient\r\n",
        "  gradient = np.zeros(10)\r\n",
        "  gradient[label] = -1 / out[label]\r\n",
        "\r\n",
        "  # Backprop\r\n",
        "  gradient = softmax.backprop(gradient, lr)\r\n",
        "  gradient = pool.backprop(gradient)\r\n",
        "  gradient = conv.backprop(gradient, lr)\r\n",
        "\r\n",
        "  return loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYn-sd5WLaDp",
        "outputId": "b7a9e9ed-53e4-40be-f577-6c4f7b7f28b1"
      },
      "source": [
        "train_images = xTrain[:1000]\r\n",
        "train_labels = yTrain[:1000]\r\n",
        "test_images = xTest[:1000]\r\n",
        "test_labels = yTest[:1000]\r\n",
        "\r\n",
        "print('MNIST CNN initialized!')\r\n",
        "\r\n",
        "# Train the CNN for 3 epochs\r\n",
        "for epoch in range(3):\r\n",
        "  print('--- Epoch %d ---' % (epoch + 1))\r\n",
        "\r\n",
        "  # Shuffle the training data\r\n",
        "  permutation = np.random.permutation(len(train_images))\r\n",
        "  train_images = train_images[permutation]\r\n",
        "  train_labels = train_labels[permutation]\r\n",
        "\r\n",
        "  # Train!\r\n",
        "  loss = 0\r\n",
        "  num_correct = 0\r\n",
        "  for i, (im, label) in enumerate(zip(train_images, train_labels)):\r\n",
        "    if i > 0 and i % 100 == 99:\r\n",
        "      print(\r\n",
        "        '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\r\n",
        "        (i + 1, loss / 100, num_correct)\r\n",
        "      )\r\n",
        "      loss = 0\r\n",
        "      num_correct = 0\r\n",
        "\r\n",
        "    l, acc = train(im, label)\r\n",
        "    loss += l\r\n",
        "    num_correct += acc\r\n",
        "\r\n",
        "# Test the CNN\r\n",
        "print('\\n--- Testing the CNN ---')\r\n",
        "loss = 0\r\n",
        "num_correct = 0\r\n",
        "for im, label in zip(test_images, test_labels):\r\n",
        "  _, l, acc = forward(im, label)\r\n",
        "  loss += l\r\n",
        "  num_correct += acc\r\n",
        "\r\n",
        "num_tests = len(test_images)\r\n",
        "print('Test Loss:', loss / num_tests)\r\n",
        "print('Test Accuracy:', num_correct / num_tests)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST CNN initialized!\n",
            "--- Epoch 1 ---\n",
            "[Step 100] Past 100 steps: Average Loss 2.215 | Accuracy: 19%\n",
            "[Step 200] Past 100 steps: Average Loss 1.966 | Accuracy: 33%\n",
            "[Step 300] Past 100 steps: Average Loss 1.459 | Accuracy: 64%\n",
            "[Step 400] Past 100 steps: Average Loss 1.087 | Accuracy: 65%\n",
            "[Step 500] Past 100 steps: Average Loss 0.862 | Accuracy: 75%\n",
            "[Step 600] Past 100 steps: Average Loss 0.914 | Accuracy: 72%\n",
            "[Step 700] Past 100 steps: Average Loss 0.688 | Accuracy: 81%\n",
            "[Step 800] Past 100 steps: Average Loss 0.684 | Accuracy: 77%\n",
            "[Step 900] Past 100 steps: Average Loss 0.745 | Accuracy: 77%\n",
            "[Step 1000] Past 100 steps: Average Loss 0.594 | Accuracy: 83%\n",
            "--- Epoch 2 ---\n",
            "[Step 100] Past 100 steps: Average Loss 0.429 | Accuracy: 89%\n",
            "[Step 200] Past 100 steps: Average Loss 0.461 | Accuracy: 85%\n",
            "[Step 300] Past 100 steps: Average Loss 0.582 | Accuracy: 85%\n",
            "[Step 400] Past 100 steps: Average Loss 0.672 | Accuracy: 78%\n",
            "[Step 500] Past 100 steps: Average Loss 0.630 | Accuracy: 80%\n",
            "[Step 600] Past 100 steps: Average Loss 0.531 | Accuracy: 83%\n",
            "[Step 700] Past 100 steps: Average Loss 0.460 | Accuracy: 87%\n",
            "[Step 800] Past 100 steps: Average Loss 0.535 | Accuracy: 82%\n",
            "[Step 900] Past 100 steps: Average Loss 0.473 | Accuracy: 84%\n",
            "[Step 1000] Past 100 steps: Average Loss 0.362 | Accuracy: 88%\n",
            "--- Epoch 3 ---\n",
            "[Step 100] Past 100 steps: Average Loss 0.315 | Accuracy: 90%\n",
            "[Step 200] Past 100 steps: Average Loss 0.420 | Accuracy: 90%\n",
            "[Step 300] Past 100 steps: Average Loss 0.488 | Accuracy: 87%\n",
            "[Step 400] Past 100 steps: Average Loss 0.408 | Accuracy: 85%\n",
            "[Step 500] Past 100 steps: Average Loss 0.404 | Accuracy: 87%\n",
            "[Step 600] Past 100 steps: Average Loss 0.346 | Accuracy: 89%\n",
            "[Step 700] Past 100 steps: Average Loss 0.305 | Accuracy: 89%\n",
            "[Step 800] Past 100 steps: Average Loss 0.488 | Accuracy: 86%\n",
            "[Step 900] Past 100 steps: Average Loss 0.496 | Accuracy: 84%\n",
            "[Step 1000] Past 100 steps: Average Loss 0.422 | Accuracy: 85%\n",
            "\n",
            "--- Testing the CNN ---\n",
            "Test Loss: 0.4905975896017013\n",
            "Test Accuracy: 0.834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLA6kArxl6K3"
      },
      "source": [
        "Observations\r\n",
        "\r\n",
        "Following along with Zhou, and working with his implementation has gave me a very solid grasp on these introductory components! This was very exciting.\r\n",
        "\r\n",
        "Some things I'd consider coming back to change (not in a particular order):\r\n",
        "\r\n",
        "1. Generalize our methods:\r\n",
        "\\\r\n",
        "For example, Conv3x3 or Conv5x5 for dim = 3 or 5\r\n",
        "\\\r\n",
        "Or perhaps a different maxpooling number\r\n",
        "2. Modify the matrix multiplication of Softmax and the attributes to be column (IF AND ONLY IF such implementation is not much more computationally taxxing)\r\n",
        "3. Cleaner and better encapsulation for the training and testing\r\n",
        "4. Completely train, then completely test. Confusion Matrix too"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQNcPDwtld_m"
      },
      "source": [
        "### Keras Equivalent of Zhou Implementation <a class=\"anchor\" id=\"three-three-five\" name=\"three-three-five\"></a> ###\r\n",
        "\r\n",
        "Please note this was done by Zhou himself, and I am simply copying it here. After implementing C-NN from the ground up, he then proceeds to make the same implementation using keras, as is found in his  [keras cnn tutorial](https://victorzhou.com/blog/keras-cnn-tutorial/). \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Updi64eTrNz1"
      },
      "source": [
        "#Importing keras utilities\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\r\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvfIHlFdldZr",
        "outputId": "415f9a0d-cd21-4678-d2a6-e14dcae6f42f"
      },
      "source": [
        "# Normalize the images.\r\n",
        "xTrain2 = (xTrain / 255) - 0.5\r\n",
        "xTest2 = (xTest / 255) - 0.5\r\n",
        "\r\n",
        "# Reshape the images.\r\n",
        "xTrain2 = np.expand_dims(xTrain2, axis=3)\r\n",
        "xTest2 = np.expand_dims(xTest2, axis=3)\r\n",
        "\r\n",
        "num_filters = 8\r\n",
        "filter_size = 3\r\n",
        "pool_size = 2\r\n",
        "\r\n",
        "# Build the model.\r\n",
        "model = Sequential([\r\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\r\n",
        "  MaxPooling2D(pool_size=pool_size),\r\n",
        "  Flatten(),\r\n",
        "  Dense(10, activation='softmax'),\r\n",
        "])\r\n",
        "\r\n",
        "# Compile the model.\r\n",
        "model.compile(\r\n",
        "  'adam',\r\n",
        "  loss='categorical_crossentropy',\r\n",
        "  metrics=['accuracy'],\r\n",
        ")\r\n",
        "\r\n",
        "# Train the model.\r\n",
        "model.fit(\r\n",
        "  xTrain2,\r\n",
        "  to_categorical(yTrain),\r\n",
        "  epochs=3,\r\n",
        "  validation_data=(xTest2, to_categorical(yTest)),\r\n",
        ")\r\n",
        "\r\n",
        "# Save the model to disk.\r\n",
        "model.save_weights('cnn.h5')\r\n",
        "\r\n",
        "# Load the model from disk later using:\r\n",
        "# model.load_weights('cnn.h5')\r\n",
        "\r\n",
        "# Predict on the first 5 test images.\r\n",
        "predictions = model.predict(xTest2[:5])\r\n",
        "\r\n",
        "# Print our model's predictions.\r\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\r\n",
        "\r\n",
        "# Check our predictions against the ground truths.\r\n",
        "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.5563 - accuracy: 0.8424 - val_loss: 0.1836 - val_accuracy: 0.9482\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1844 - accuracy: 0.9476 - val_loss: 0.1357 - val_accuracy: 0.9592\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1271 - accuracy: 0.9636 - val_loss: 0.1042 - val_accuracy: 0.9682\n",
            "[7 2 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2vWAkWVvsww"
      },
      "source": [
        "Awesome! So we implemented CNN from the ground up using numpy, and also using keras, working to an accuracy of roughly 96 to 97 percent. \r\n",
        "\r\n",
        "What if we consider more questions regarding our C-NN architecture:\r\n",
        "\r\n",
        "We should consider playing around with other conv, maxpool, and softmax sizes/layers, and what if we include more/less layers? \r\n",
        "\r\n",
        "What else can we add to the model? What about dropout layers? Fully connected, or no?\r\n",
        "\r\n",
        "Lots of questions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPHldywkxeN6"
      },
      "source": [
        "## Official Keras CNN Example <a class=\"anchor\" id=\"three-four\" name=\"three-four\"></a> ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLuir31YzK0d"
      },
      "source": [
        "The [keras documentation](https://keras.io/getting_started/) provides a 99% accurate [example of CNN](https://keras.io/examples/vision/mnist_convnet/) for the MNIST database.\r\n",
        "\r\n",
        "The example features mostly the same architecture as prior but with some modification:\r\n",
        "1. There are two convolutional layers\r\n",
        "2. Convolutional layers have 32 and 64 filters of (same) size 3x3\r\n",
        "2. A dropout layer is introduced\r\n",
        "4. 15 epochs instead of 3\r\n",
        "5. Batch normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT6nCllX2y2F"
      },
      "source": [
        "These seem like fairly reasonable additions to our architecture. \r\n",
        "\r\n",
        "My primary question is \"why\" this architecture. What inferences about our data lead us to say $k_1$ filters is better than $k_2$ filters? What kind of inferences can we make prior to model construction to give us insight onto the appropriate number of filters, layers, and so forth, regarding neural networks?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M4tN3uB2yW5"
      },
      "source": [
        "#Importing\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvMBa8pUl5LM"
      },
      "source": [
        "#Importing MNIST data from keras\r\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB7ULdA9l91R"
      },
      "source": [
        "#Converting to int32; forcing to 0-255 from uint8 causes error when subtraction leads to a negative value\r\n",
        "xTrain = x_train.astype(np.int32)\r\n",
        "yTrain = y_train.astype(np.int32)\r\n",
        "xTest = x_test.astype(np.int32)\r\n",
        "yTest = y_test.astype(np.int32)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjFbCbqLkUzB"
      },
      "source": [
        "# Model / data parameters\r\n",
        "num_classes = 10\r\n",
        "input_shape = (28, 28, 1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGS4k3mrkU1X"
      },
      "source": [
        "#Preprocessing the data\r\n",
        "\r\n",
        "# Scale images to the [0, 1] range\r\n",
        "xTrain = xTrain.astype(\"float32\") / 255\r\n",
        "xTest = xTest.astype(\"float32\") / 255\r\n",
        "\r\n",
        "# Make sure images have shape (28, 28, 1)\r\n",
        "xTrain = np.expand_dims(xTrain, -1)\r\n",
        "xTest = np.expand_dims(xTest, -1)\r\n",
        "\r\n",
        "# convert class vectors to binary class matrices\r\n",
        "yTrain = keras.utils.to_categorical(yTrain, num_classes)\r\n",
        "yTest = keras.utils.to_categorical(yTest, num_classes)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG_O8udIlP5T",
        "outputId": "b2fab027-7e88-4b1b-8fc8-8cc2b5f5af7e"
      },
      "source": [
        "xTrain.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85nurDMM38mF"
      },
      "source": [
        "#building the model\r\n",
        "\r\n",
        "model = keras.Sequential(\r\n",
        "    [\r\n",
        "        keras.Input(shape=input_shape),\r\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\r\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\r\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
        "        layers.Flatten(),\r\n",
        "        layers.Dropout(0.5),\r\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\r\n",
        "    ]\r\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIyRXhaVzKdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96bc440-7ce2-4d04-c9c4-3d74f8504901"
      },
      "source": [
        "#Defining batch size and number of epochs\r\n",
        "batch_size = 128\r\n",
        "epochs = 15\r\n",
        "\r\n",
        "#compile the model with corss entorpy loss\r\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n",
        "#Fit the model with batch normalization and validation splitting\r\n",
        "model.fit(xTrain, yTrain, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 40s 93ms/step - loss: 0.7473 - accuracy: 0.7690 - val_loss: 0.0717 - val_accuracy: 0.9800\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 39s 93ms/step - loss: 0.1178 - accuracy: 0.9637 - val_loss: 0.0539 - val_accuracy: 0.9848\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 39s 93ms/step - loss: 0.0861 - accuracy: 0.9726 - val_loss: 0.0461 - val_accuracy: 0.9875\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0710 - accuracy: 0.9782 - val_loss: 0.0416 - val_accuracy: 0.9898\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0601 - accuracy: 0.9815 - val_loss: 0.0363 - val_accuracy: 0.9902\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0545 - accuracy: 0.9834 - val_loss: 0.0376 - val_accuracy: 0.9880\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0515 - accuracy: 0.9844 - val_loss: 0.0344 - val_accuracy: 0.9900\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0443 - accuracy: 0.9864 - val_loss: 0.0331 - val_accuracy: 0.9905\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.0326 - val_accuracy: 0.9910\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 39s 93ms/step - loss: 0.0414 - accuracy: 0.9869 - val_loss: 0.0316 - val_accuracy: 0.9917\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 39s 93ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 0.0314 - val_accuracy: 0.9915\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0369 - accuracy: 0.9876 - val_loss: 0.0288 - val_accuracy: 0.9917\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0331 - accuracy: 0.9893 - val_loss: 0.0299 - val_accuracy: 0.9925\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 0.0319 - val_accuracy: 0.9917\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 40s 94ms/step - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.0317 - val_accuracy: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f39a8325fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0DrEoKfzKf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133cf1ce-6fc5-4c49-d858-a97a52d0d7e0"
      },
      "source": [
        "#Evaluating the model against test data\r\n",
        "score = model.evaluate(xTest, yTest, verbose=0)\r\n",
        "print(\"Test loss:\", score[0])\r\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.02281571738421917\n",
            "Test accuracy: 0.9927999973297119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YKhmfIqxg7a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzKm8LnOxg9r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}