{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import idx2numpy #For loading data; idx-ubyte to nparray\n",
    "\n",
    "import matplotlib.pyplot as plt #Visualizing data \n",
    "from collections import Counter #Dependancy for my majority vote method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose to import via exact directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/marco/Desktop/godBless/samples2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I manually choose each path like a madlad\n",
    "fileTrainX = '/home/marco/Desktop/godBless/samples2/train-images-idx3-ubyte'\n",
    "fileTrainY = '/home/marco/Desktop/godBless/samples2/train-labels-idx1-ubyte'\n",
    "fileTestX = '/home/marco/Desktop/godBless/samples2/t10k-images-idx3-ubyte'\n",
    "fileTestY = '/home/marco/Desktop/godBless/samples2/t10k-labels-idx1-ubyte'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the data through numpy \n",
    "# trainX - 60k 28x28 grayscale images  (60000, 28, 28)\n",
    "# trainY - 60k digit labels (60000,)\n",
    "# trainX - 10k grayscale 28x28 images (10000, 28, 28)\n",
    "# trainY - 10k digit labels (10000,)\n",
    "\n",
    "trainX = idx2numpy.convert_from_file(fileTrainX)\n",
    "trainY = idx2numpy.convert_from_file(fileTrainY)\n",
    "testX = idx2numpy.convert_from_file(fileTestX)\n",
    "testY = idx2numpy.convert_from_file(fileTestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "#Verifying basic correctness\n",
    "print('X_train: ' + str(trainX.shape))\n",
    "print('Y_train: ' + str(trainY.shape))\n",
    "print('X_test:  '  + str(testX.shape))\n",
    "print('Y_test:  '  + str(testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alright, looks like we got it!\n",
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Alright, let's just see some!\n",
    "for i in range(1,10):  \n",
    "    plt.subplot(3,3,i)\n",
    "    plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\n",
    "    #plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faeb838d438>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#If we want to inspect a specific image at index k:\n",
    "secondDigit = trainX[1]\n",
    "plt.imshow(secondDigit, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It's value will relate with the same index : YEUP it's a zero!\n",
    "trainY[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 5421,\n",
       "         0: 5923,\n",
       "         4: 5842,\n",
       "         1: 6742,\n",
       "         9: 5949,\n",
       "         2: 5958,\n",
       "         3: 6131,\n",
       "         6: 5918,\n",
       "         7: 6265,\n",
       "         8: 5851})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabelDict = Counter(trainY)\n",
    "trainLabelDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Just to show that it seems the digits are roughly uniformly distributed\n",
    "plt.bar(range(len(trainLabelDict)), list(trainLabelDict.values()), align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the test digits to be in the form of int32 (rather than uint8)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testXArr = testX.astype(np.int32)\n",
    "testXArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 2., 1., ..., 4., 5., 6.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testYArr = testY.astype(np.double)\n",
    "testYArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testYArr = testY.astype(np.int32)\n",
    "testYArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainXArr = trainX.astype(np.int32)\n",
    "trainXArr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainYArr = trainY.astype(np.int32)\n",
    "trainYArr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testYArr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 150, 253, 202,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 197, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 190, 251, 251, 251, 253, 169, 109,  62,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 251, 251, 251, 251, 253, 251, 251, 220,  51,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 255, 253, 253, 253, 253, 234, 222, 253, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  63, 221, 253, 251, 251, 251, 147,  77,  62, 128, 251, 251, 105,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  32, 231, 251, 253, 251, 220, 137,  10,   0,   0,  31, 230, 251, 243, 113,   5,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 188,  20,   0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 201,  30,   0,   0,   0,   0,   0,   0,  31, 200, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0,  32, 202, 255, 253, 164,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 251, 251,   0,   0,   0,   0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0,   0,  21,  63, 231, 251, 253, 230,  30,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0,   0, 144, 251, 251, 251, 221,  61,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0, 182, 221, 251, 251, 251, 180,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 218, 253, 253,  73,  73, 228, 253, 253, 255, 253, 253, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 113, 251, 251, 253, 251, 251, 251, 251, 253, 251, 251, 251, 147,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  31, 230, 251, 253, 251, 251, 251, 251, 253, 230, 189,  35,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  62, 142, 253, 251, 251, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  72, 174, 251, 173,  71,  72,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testXArr[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980.683972773042"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This can't be done until method cell below is ran\n",
    "euclidean_distance(testXArr[3],trainX[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall\n",
    "# trainX - 60k 28x28 grayscale images  (60000, 28, 28)\n",
    "# trainY - 60k digit labels (60000,)\n",
    "# trainX - 10k grayscale 28x28 images (10000, 28, 28)\n",
    "# trainY - 10k digit labels (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(p, q):\n",
    "    \"\"\"\n",
    "    INPUT: Matrix images p,q\n",
    "    OUTPUT: Euclidian distance sum ((p-q)**2)\n",
    "    Note: Be wary of uint8-uint8 due to overflow at negative.\n",
    "    \"\"\"\n",
    "    # element-wise computations are automatically handled by numpy\n",
    "    return ( np.sqrt(np.sum((p-q)**2)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Majority K Voting\n",
    "\n",
    "def findMajority(labels):\n",
    "    \"\"\"\n",
    "    INPUT: list of k labels most similar to that particular image p.\n",
    "    OUTPUT: The value of the greatest count.\n",
    "    Dependancy: Requires Counter from collections.\n",
    "    Note: If there is a tie, it takes the first max value along the dictionary.\n",
    "    Method Usage: Method for Majority K Voting.\n",
    "    \"\"\"\n",
    "    #Counter to create dictionary and count\n",
    "    labelDict = Counter(labels)\n",
    "    \n",
    "    #Max of the dictionary\n",
    "    labelMax = max(labelDict.values())\n",
    "    \n",
    "    #Iterate through to find key (and majority class)\n",
    "    for key, value in labelDict.items():\n",
    "        if value == labelMax:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictOneDigit(k, trainSet, trainLabels, testDigit):\n",
    "    \"\"\"\n",
    "    INPUT: k nearest neighbors, training set, training labels, test set.\n",
    "    OUTPUT: Returns a classification based on euclidean distance for a test digit.\n",
    "    Dependencies: Counter (in majority vote)\n",
    "    \"\"\"\n",
    "    \n",
    "    #For a single testDigit, compute its euclidean distance versus entire train set\n",
    "    distances = [euclidean_distance(testDigit,trainSet[i]) for i in range(len(trainSet))]\n",
    "    \n",
    "    #Tuple distances array with labels\n",
    "    tupledDistances = np.array(list(zip(trainLabels,distances)))\n",
    "    \n",
    "    #Sort the (this is more expensive than needed)\n",
    "    sortedDistances = sorted(tupledDistances, key=lambda tup: tup[1])\n",
    "    \n",
    "    #Extract out k labels\n",
    "    kLabels = [label for (label,_) in sortedDistances[:k]]\n",
    "    \n",
    "    #Return the classified label by maority vote (size k)\n",
    "    return (findMajority(kLabels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictOneDigit(10,trainX,trainY,testXArr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = [predictOneDigit(10,trainX,trainY,testXArr[i]) for i in range(50)]\n",
    "predictions1 = np.array(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 1, 3, 5, 1, 2, 4, 4])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2, 4, 4])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testYArr[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolArr = testYArr[0:50] == predictions1\n",
    "boolArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countBool(lst): \n",
    "    return sum(bool(x) for x in lst) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-684ac77201e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountBool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboolArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboolArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-103-dbda386b9c4f>\u001b[0m in \u001b[0;36mcountBool\u001b[0;34m(lst)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcountBool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "accuracy = countBool(boolArr)/ len(boolArr)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#60k training set, first 1k test set\n",
    "#Hyper paramaterization of KNN\n",
    "Accuracy for 1 : 0.9620\n",
    "Accuracy for 2 : 0.9620\n",
    "Accuracy for 3 : 0.9650\n",
    "Accuracy for 4 : 0.9640\n",
    "Accuracy for 5 : 0.9630\n",
    "Accuracy for 6 : 0.9640\n",
    "Accuracy for 7 : 0.9630\n",
    "Accuracy for 8 : 0.9620\n",
    "Accuracy for 9 : 0.9540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5a113006476a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myoya\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mya\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "list(range())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = np.delete(trainX, range(6000,12000),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 28, 28)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = np.zeros(5)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30000/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX[0:12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k folds for first half of data (just to save time; I just wanted to demonstrate technique of )\n",
    "addition = 6000\n",
    "start = 0\n",
    "end = addition\n",
    "\n",
    "errors = np.zeros(5)\n",
    "\n",
    "for k in range(5):\n",
    "    \n",
    "    trainingX = np.delete(trainXArr, range(start,end),axis=0)\n",
    "    trainingY = np.delete(trainYArr, range(start,end),axis=0)\n",
    "    \n",
    "    validationX = trainXArr[start:end]\n",
    "    validationY = trainYArr[start:end]\n",
    "    predictions = [predictOneDigit(1,trainingX,trainingY,validationX[i]) for i in range(len(validationX))]\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    boolArr = validationY == predictions\n",
    "    \n",
    "    accuracy = countBool(boolArr)/ len(boolArr)\n",
    "    \n",
    "    print(start,end)\n",
    "    start = start + addition\n",
    "    end = end + addition\n",
    "    \n",
    "    print(\"Accuracy Score for %d : %.4f\"%(k, accuracy) )\n",
    "    errors[k] = accuracy\n",
    "    \n",
    "print(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolArr = predictions == validationY[0:6000]\n",
    "boolArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3006666666666667"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = countBool(boolArr)/ len(boolArr)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12000\n",
      "12000 24000\n",
      "24000 36000\n",
      "36000 48000\n",
      "48000 60000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = 0\n",
    "end = 12000\n",
    "\n",
    "for k in range(5):\n",
    "    print(start,end)\n",
    "    start = start + 12000\n",
    "    end = end+12000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 1 : 0.9620\n",
      "Accuracy for 2 : 0.9620\n",
      "Accuracy for 3 : 0.9650\n",
      "Accuracy for 4 : 0.9640\n",
      "Accuracy for 5 : 0.9630\n",
      "Accuracy for 6 : 0.9640\n",
      "Accuracy for 7 : 0.9630\n",
      "Accuracy for 8 : 0.9620\n",
      "Accuracy for 9 : 0.9540\n"
     ]
    }
   ],
   "source": [
    "#Hyperparamaterization based on first 2000 test results for each k from 1 to 9\n",
    "for k in range(1,10):\n",
    "    #Performing KNN for K\n",
    "    predictions1 = [predictOneDigit(k,trainX,trainY,testXArr[i]) for i in range(1000)]\n",
    "    predictions1 = np.array(predictions1)\n",
    "    \n",
    "    boolArr = testYArr[0:1000] == predictions1\n",
    "    \n",
    "    accuracy = countBool(boolArr)/ len(boolArr)\n",
    "    \n",
    "    print(\"Accuracy for %d : %.4f\"%(k, accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 1 : 0.10\n",
      "Accuracy for 2 : 0.20\n",
      "Accuracy for 3 : 0.30\n",
      "Accuracy for 4 : 0.40\n",
      "Accuracy for 5 : 0.50\n",
      "Accuracy for 6 : 0.60\n",
      "Accuracy for 7 : 0.70\n",
      "Accuracy for 8 : 0.80\n",
      "Accuracy for 9 : 0.90\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,10):\n",
    "    accuracy = k/10\n",
    "    print(\"Accuracy for %d : %.2f\"%(k, accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Accuracy for 1 : 0.9620\n",
    "Accuracy for 2 : 0.9620\n",
    "Accuracy for 3 : 0.9650\n",
    "Accuracy for 4 : 0.9640\n",
    "Accuracy for 5 : 0.9630\n",
    "Accuracy for 6 : 0.9640\n",
    "Accuracy for 7 : 0.9630\n",
    "Accuracy for 8 : 0.9620\n",
    "Accuracy for 9 : 0.9540\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-305-52209e29a0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#The entire K-NN Algorithm in one line cheeky cheeky for k=10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredictOneDigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestXArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestYArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-305-52209e29a0d7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#The entire K-NN Algorithm in one line cheeky cheeky for k=10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpredictOneDigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestXArr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestYArr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-267-4feee07c8c92>\u001b[0m in \u001b[0;36mpredictOneDigit\u001b[0;34m(k, trainSet, trainLabels, testDigit)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#For a single testDigit, compute its euclidean distance versus entire train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meuclidean_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDigit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Tuple distances array with labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-267-4feee07c8c92>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#For a single testDigit, compute its euclidean distance versus entire train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0meuclidean_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDigit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Tuple distances array with labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-74b5838bb9da>\u001b[0m in \u001b[0;36meuclidean_distance\u001b[0;34m(p, q)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# element-wise computations are automatically handled by numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#The entire K-NN Algorithm in one line cheeky cheeky for k=10\n",
    "predictions = [predictOneDigit(10,trainX,trainY,testXArr[i]) for i in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictOneDigitQuick(k, trainSet, trainLabels, testDigit):\n",
    "    \"\"\"\n",
    "    INPUT: k nearest neighbors, training set, training labels, test set.\n",
    "    OUTPUT: Returns a classification based on euclidean distance for a test digit.\n",
    "    Dependencies: Counter (in majority vote)\n",
    "    \"\"\"\n",
    "    \n",
    "    #For a single testDigit, compute its euclidean distance versus entire train set\n",
    "    distances = [euclidean_distance(testDigit,trainSet[i]) for i in range(len(trainX))]\n",
    "    \n",
    "    #Tuple distances array with labels\n",
    "    tupledDistances = np.array(list(zip(trainLabels,distances)))\n",
    "    \n",
    "    #Sort the (this is more expensive than needed)\n",
    "    #sortedDistances = sorted(tupledDistances, key=lambda tup: tup[1])\n",
    "    \n",
    "    sortedDistances = smallestKInTuple(tupledDistances,k)\n",
    "    \n",
    "    #Extract out k labels\n",
    "    kLabels = [label for (label,_) in sortedDistances[:k]]\n",
    "    \n",
    "    #Return the classified label by maority vote (size k)\n",
    "    return (findMajority(kLabels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locally at: 0\n",
      "locally at: 10\n",
      "locally at: 20\n",
      "locally at: 30\n",
      "locally at: 40\n",
      "locally at: 50\n",
      "locally at: 60\n",
      "locally at: 70\n",
      "locally at: 80\n",
      "locally at: 90\n",
      "--- 64.744877576828 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#I attempt my version with only finding minimum k\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#predictions = np.zeros(len(testYArr))\n",
    "predictions1 = np.zeros(100)\n",
    "for i in range(100):\n",
    "    predictions1[i] = predictOneDigitQuick(10,trainX,trainY,testXArr[i])\n",
    "    if(i % 10 == 0):\n",
    "        print(\"locally at:\",i)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locally at: 0\n",
      "locally at: 10\n",
      "locally at: 20\n",
      "locally at: 30\n",
      "locally at: 40\n",
      "locally at: 50\n",
      "locally at: 60\n",
      "locally at: 70\n",
      "locally at: 80\n",
      "locally at: 90\n",
      "--- 66.22034406661987 seconds ---\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locally at: 0\n",
      "locally at: 10\n",
      "locally at: 20\n",
      "locally at: 30\n",
      "locally at: 40\n",
      "locally at: 50\n",
      "locally at: 60\n",
      "locally at: 70\n",
      "locally at: 80\n",
      "locally at: 90\n",
      "locally at: 100\n",
      "locally at: 110\n",
      "locally at: 120\n",
      "locally at: 130\n",
      "locally at: 140\n",
      "locally at: 150\n",
      "locally at: 160\n",
      "locally at: 170\n",
      "locally at: 180\n",
      "locally at: 190\n",
      "locally at: 200\n",
      "locally at: 210\n",
      "locally at: 220\n",
      "locally at: 230\n",
      "locally at: 240\n",
      "locally at: 250\n",
      "locally at: 260\n",
      "locally at: 270\n",
      "locally at: 280\n",
      "locally at: 290\n",
      "locally at: 300\n",
      "locally at: 310\n",
      "locally at: 320\n",
      "locally at: 330\n",
      "locally at: 340\n",
      "locally at: 350\n",
      "locally at: 360\n",
      "locally at: 370\n",
      "locally at: 380\n",
      "locally at: 390\n",
      "locally at: 400\n",
      "locally at: 410\n",
      "locally at: 420\n",
      "locally at: 430\n",
      "locally at: 440\n",
      "locally at: 450\n",
      "locally at: 460\n",
      "locally at: 470\n",
      "locally at: 480\n",
      "locally at: 490\n",
      "locally at: 500\n",
      "locally at: 510\n",
      "locally at: 520\n",
      "locally at: 530\n",
      "locally at: 540\n",
      "locally at: 550\n",
      "locally at: 560\n",
      "locally at: 570\n",
      "locally at: 580\n",
      "locally at: 590\n",
      "locally at: 600\n",
      "locally at: 610\n",
      "locally at: 620\n",
      "locally at: 630\n",
      "locally at: 640\n",
      "locally at: 650\n",
      "locally at: 660\n",
      "locally at: 670\n",
      "locally at: 680\n",
      "locally at: 690\n",
      "locally at: 700\n",
      "locally at: 710\n",
      "locally at: 720\n",
      "locally at: 730\n",
      "locally at: 740\n",
      "locally at: 750\n",
      "locally at: 760\n",
      "locally at: 770\n",
      "locally at: 780\n",
      "locally at: 790\n",
      "locally at: 800\n",
      "locally at: 810\n",
      "locally at: 820\n",
      "locally at: 830\n",
      "locally at: 840\n",
      "locally at: 850\n",
      "locally at: 860\n",
      "locally at: 870\n",
      "locally at: 880\n",
      "locally at: 890\n",
      "locally at: 900\n",
      "locally at: 910\n",
      "locally at: 920\n",
      "locally at: 930\n",
      "locally at: 940\n",
      "locally at: 950\n",
      "locally at: 960\n",
      "locally at: 970\n",
      "locally at: 980\n",
      "locally at: 990\n",
      "locally at: 1000\n",
      "locally at: 1010\n",
      "locally at: 1020\n",
      "locally at: 1030\n",
      "locally at: 1040\n",
      "locally at: 1050\n",
      "locally at: 1060\n",
      "locally at: 1070\n",
      "locally at: 1080\n",
      "locally at: 1090\n",
      "locally at: 1100\n",
      "locally at: 1110\n",
      "locally at: 1120\n",
      "locally at: 1130\n",
      "locally at: 1140\n",
      "locally at: 1150\n",
      "locally at: 1160\n",
      "locally at: 1170\n",
      "locally at: 1180\n",
      "locally at: 1190\n",
      "locally at: 1200\n",
      "locally at: 1210\n",
      "locally at: 1220\n",
      "locally at: 1230\n",
      "locally at: 1240\n",
      "locally at: 1250\n",
      "locally at: 1260\n",
      "locally at: 1270\n",
      "locally at: 1280\n",
      "locally at: 1290\n",
      "locally at: 1300\n",
      "locally at: 1310\n",
      "locally at: 1320\n",
      "locally at: 1330\n",
      "locally at: 1340\n",
      "locally at: 1350\n",
      "locally at: 1360\n",
      "locally at: 1370\n",
      "locally at: 1380\n",
      "locally at: 1390\n",
      "locally at: 1400\n",
      "locally at: 1410\n",
      "locally at: 1420\n",
      "locally at: 1430\n",
      "locally at: 1440\n",
      "locally at: 1450\n",
      "locally at: 1460\n",
      "locally at: 1470\n",
      "locally at: 1480\n",
      "locally at: 1490\n",
      "locally at: 1500\n",
      "locally at: 1510\n",
      "locally at: 1520\n",
      "locally at: 1530\n",
      "locally at: 1540\n",
      "locally at: 1550\n",
      "locally at: 1560\n",
      "locally at: 1570\n",
      "locally at: 1580\n",
      "locally at: 1590\n",
      "locally at: 1600\n",
      "locally at: 1610\n",
      "locally at: 1620\n",
      "locally at: 1630\n",
      "locally at: 1640\n",
      "locally at: 1650\n",
      "locally at: 1660\n",
      "locally at: 1670\n",
      "locally at: 1680\n",
      "locally at: 1690\n",
      "locally at: 1700\n",
      "locally at: 1710\n",
      "locally at: 1720\n",
      "locally at: 1730\n",
      "locally at: 1740\n",
      "locally at: 1750\n",
      "locally at: 1760\n",
      "locally at: 1770\n",
      "locally at: 1780\n",
      "locally at: 1790\n",
      "locally at: 1800\n",
      "locally at: 1810\n",
      "locally at: 1820\n",
      "locally at: 1830\n",
      "locally at: 1840\n",
      "locally at: 1850\n",
      "locally at: 1860\n",
      "locally at: 1870\n",
      "locally at: 1880\n",
      "locally at: 1890\n",
      "locally at: 1900\n",
      "locally at: 1910\n",
      "locally at: 1920\n",
      "locally at: 1930\n",
      "locally at: 1940\n",
      "locally at: 1950\n",
      "locally at: 1960\n",
      "locally at: 1970\n",
      "locally at: 1980\n",
      "locally at: 1990\n",
      "locally at: 2000\n",
      "locally at: 2010\n",
      "locally at: 2020\n",
      "locally at: 2030\n",
      "locally at: 2040\n",
      "locally at: 2050\n",
      "locally at: 2060\n",
      "locally at: 2070\n",
      "locally at: 2080\n",
      "locally at: 2090\n",
      "locally at: 2100\n",
      "locally at: 2110\n",
      "locally at: 2120\n",
      "locally at: 2130\n",
      "locally at: 2140\n",
      "locally at: 2150\n",
      "locally at: 2160\n",
      "locally at: 2170\n",
      "locally at: 2180\n",
      "locally at: 2190\n",
      "locally at: 2200\n",
      "locally at: 2210\n",
      "locally at: 2220\n",
      "locally at: 2230\n",
      "locally at: 2240\n",
      "locally at: 2250\n",
      "locally at: 2260\n",
      "locally at: 2270\n",
      "locally at: 2280\n",
      "locally at: 2290\n",
      "locally at: 2300\n",
      "locally at: 2310\n",
      "locally at: 2320\n",
      "locally at: 2330\n",
      "locally at: 2340\n",
      "locally at: 2350\n",
      "locally at: 2360\n",
      "locally at: 2370\n",
      "locally at: 2380\n",
      "locally at: 2390\n",
      "locally at: 2400\n",
      "locally at: 2410\n",
      "locally at: 2420\n",
      "locally at: 2430\n",
      "locally at: 2440\n",
      "locally at: 2450\n",
      "locally at: 2460\n",
      "locally at: 2470\n",
      "locally at: 2480\n",
      "locally at: 2490\n",
      "locally at: 2500\n",
      "locally at: 2510\n",
      "locally at: 2520\n",
      "locally at: 2530\n",
      "locally at: 2540\n",
      "locally at: 2550\n",
      "locally at: 2560\n",
      "locally at: 2570\n",
      "locally at: 2580\n",
      "locally at: 2590\n",
      "locally at: 2600\n",
      "locally at: 2610\n",
      "locally at: 2620\n",
      "locally at: 2630\n",
      "locally at: 2640\n",
      "locally at: 2650\n",
      "locally at: 2660\n",
      "locally at: 2670\n",
      "locally at: 2680\n",
      "locally at: 2690\n",
      "locally at: 2700\n",
      "locally at: 2710\n",
      "locally at: 2720\n",
      "locally at: 2730\n",
      "locally at: 2740\n",
      "locally at: 2750\n",
      "locally at: 2760\n",
      "locally at: 2770\n",
      "locally at: 2780\n",
      "locally at: 2790\n",
      "locally at: 2800\n",
      "locally at: 2810\n",
      "locally at: 2820\n",
      "locally at: 2830\n",
      "locally at: 2840\n",
      "locally at: 2850\n",
      "locally at: 2860\n",
      "locally at: 2870\n",
      "locally at: 2880\n",
      "locally at: 2890\n",
      "locally at: 2900\n",
      "locally at: 2910\n",
      "locally at: 2920\n",
      "locally at: 2930\n",
      "locally at: 2940\n",
      "locally at: 2950\n",
      "locally at: 2960\n",
      "locally at: 2970\n",
      "locally at: 2980\n",
      "locally at: 2990\n",
      "locally at: 3000\n",
      "locally at: 3010\n",
      "locally at: 3020\n",
      "locally at: 3030\n",
      "locally at: 3040\n",
      "locally at: 3050\n",
      "locally at: 3060\n",
      "locally at: 3070\n",
      "locally at: 3080\n",
      "locally at: 3090\n",
      "locally at: 3100\n",
      "locally at: 3110\n",
      "locally at: 3120\n",
      "locally at: 3130\n",
      "locally at: 3140\n",
      "locally at: 3150\n",
      "locally at: 3160\n",
      "locally at: 3170\n",
      "locally at: 3180\n",
      "locally at: 3190\n",
      "locally at: 3200\n",
      "locally at: 3210\n",
      "locally at: 3220\n",
      "locally at: 3230\n",
      "locally at: 3240\n",
      "locally at: 3250\n",
      "locally at: 3260\n",
      "locally at: 3270\n",
      "locally at: 3280\n",
      "locally at: 3290\n",
      "locally at: 3300\n",
      "locally at: 3310\n",
      "locally at: 3320\n",
      "locally at: 3330\n",
      "locally at: 3340\n",
      "locally at: 3350\n",
      "locally at: 3360\n",
      "locally at: 3370\n",
      "locally at: 3380\n",
      "locally at: 3390\n",
      "locally at: 3400\n",
      "locally at: 3410\n",
      "locally at: 3420\n",
      "locally at: 3430\n",
      "locally at: 3440\n",
      "locally at: 3450\n",
      "locally at: 3460\n",
      "locally at: 3470\n",
      "locally at: 3480\n",
      "locally at: 3490\n",
      "locally at: 3500\n",
      "locally at: 3510\n",
      "locally at: 3520\n",
      "locally at: 3530\n",
      "locally at: 3540\n",
      "locally at: 3550\n",
      "locally at: 3560\n",
      "locally at: 3570\n",
      "locally at: 3580\n",
      "locally at: 3590\n",
      "locally at: 3600\n",
      "locally at: 3610\n",
      "locally at: 3620\n",
      "locally at: 3630\n",
      "locally at: 3640\n",
      "locally at: 3650\n",
      "locally at: 3660\n",
      "locally at: 3670\n",
      "locally at: 3680\n",
      "locally at: 3690\n",
      "locally at: 3700\n",
      "locally at: 3710\n",
      "locally at: 3720\n",
      "locally at: 3730\n",
      "locally at: 3740\n",
      "locally at: 3750\n",
      "locally at: 3760\n",
      "locally at: 3770\n",
      "locally at: 3780\n",
      "locally at: 3790\n",
      "locally at: 3800\n",
      "locally at: 3810\n",
      "locally at: 3820\n",
      "locally at: 3830\n",
      "locally at: 3840\n",
      "locally at: 3850\n",
      "locally at: 3860\n",
      "locally at: 3870\n",
      "locally at: 3880\n",
      "locally at: 3890\n",
      "locally at: 3900\n",
      "locally at: 3910\n",
      "locally at: 3920\n",
      "locally at: 3930\n",
      "locally at: 3940\n",
      "locally at: 3950\n",
      "locally at: 3960\n",
      "locally at: 3970\n",
      "locally at: 3980\n",
      "locally at: 3990\n",
      "locally at: 4000\n",
      "locally at: 4010\n",
      "locally at: 4020\n",
      "locally at: 4030\n",
      "locally at: 4040\n",
      "locally at: 4050\n",
      "locally at: 4060\n",
      "locally at: 4070\n",
      "locally at: 4080\n",
      "locally at: 4090\n",
      "locally at: 4100\n",
      "locally at: 4110\n",
      "locally at: 4120\n",
      "locally at: 4130\n",
      "locally at: 4140\n",
      "locally at: 4150\n",
      "locally at: 4160\n",
      "locally at: 4170\n",
      "locally at: 4180\n",
      "locally at: 4190\n",
      "locally at: 4200\n",
      "locally at: 4210\n",
      "locally at: 4220\n",
      "locally at: 4230\n",
      "locally at: 4240\n",
      "locally at: 4250\n",
      "locally at: 4260\n",
      "locally at: 4270\n",
      "locally at: 4280\n",
      "locally at: 4290\n",
      "locally at: 4300\n",
      "locally at: 4310\n",
      "locally at: 4320\n",
      "locally at: 4330\n",
      "locally at: 4340\n",
      "locally at: 4350\n",
      "locally at: 4360\n",
      "locally at: 4370\n",
      "locally at: 4380\n",
      "locally at: 4390\n",
      "locally at: 4400\n",
      "locally at: 4410\n",
      "locally at: 4420\n",
      "locally at: 4430\n",
      "locally at: 4440\n",
      "locally at: 4450\n",
      "locally at: 4460\n",
      "locally at: 4470\n",
      "locally at: 4480\n",
      "locally at: 4490\n",
      "locally at: 4500\n",
      "locally at: 4510\n",
      "locally at: 4520\n",
      "locally at: 4530\n",
      "locally at: 4540\n",
      "locally at: 4550\n",
      "locally at: 4560\n",
      "locally at: 4570\n",
      "locally at: 4580\n",
      "locally at: 4590\n",
      "locally at: 4600\n",
      "locally at: 4610\n",
      "locally at: 4620\n",
      "locally at: 4630\n",
      "locally at: 4640\n",
      "locally at: 4650\n",
      "locally at: 4660\n",
      "locally at: 4670\n",
      "locally at: 4680\n",
      "locally at: 4690\n",
      "locally at: 4700\n",
      "locally at: 4710\n",
      "locally at: 4720\n",
      "locally at: 4730\n",
      "locally at: 4740\n",
      "locally at: 4750\n",
      "locally at: 4760\n",
      "locally at: 4770\n",
      "locally at: 4780\n",
      "locally at: 4790\n",
      "locally at: 4800\n",
      "locally at: 4810\n",
      "locally at: 4820\n",
      "locally at: 4830\n",
      "locally at: 4840\n",
      "locally at: 4850\n",
      "locally at: 4860\n",
      "locally at: 4870\n",
      "locally at: 4880\n",
      "locally at: 4890\n",
      "locally at: 4900\n",
      "locally at: 4910\n",
      "locally at: 4920\n",
      "locally at: 4930\n",
      "locally at: 4940\n",
      "locally at: 4950\n",
      "locally at: 4960\n",
      "locally at: 4970\n",
      "locally at: 4980\n",
      "locally at: 4990\n",
      "locally at: 5000\n",
      "locally at: 5010\n",
      "locally at: 5020\n",
      "locally at: 5030\n",
      "locally at: 5040\n",
      "locally at: 5050\n",
      "locally at: 5060\n",
      "locally at: 5070\n",
      "locally at: 5080\n",
      "locally at: 5090\n",
      "locally at: 5100\n",
      "locally at: 5110\n",
      "locally at: 5120\n",
      "locally at: 5130\n",
      "locally at: 5140\n",
      "locally at: 5150\n",
      "locally at: 5160\n",
      "locally at: 5170\n",
      "locally at: 5180\n",
      "locally at: 5190\n",
      "locally at: 5200\n",
      "locally at: 5210\n",
      "locally at: 5220\n",
      "locally at: 5230\n",
      "locally at: 5240\n",
      "locally at: 5250\n",
      "locally at: 5260\n",
      "locally at: 5270\n",
      "locally at: 5280\n",
      "locally at: 5290\n",
      "locally at: 5300\n",
      "locally at: 5310\n",
      "locally at: 5320\n",
      "locally at: 5330\n",
      "locally at: 5340\n",
      "locally at: 5350\n",
      "locally at: 5360\n",
      "locally at: 5370\n",
      "locally at: 5380\n",
      "locally at: 5390\n",
      "locally at: 5400\n",
      "locally at: 5410\n",
      "locally at: 5420\n",
      "locally at: 5430\n",
      "locally at: 5440\n",
      "locally at: 5450\n",
      "locally at: 5460\n",
      "locally at: 5470\n",
      "locally at: 5480\n",
      "locally at: 5490\n",
      "locally at: 5500\n",
      "locally at: 5510\n",
      "locally at: 5520\n",
      "locally at: 5530\n",
      "locally at: 5540\n",
      "locally at: 5550\n",
      "locally at: 5560\n",
      "locally at: 5570\n",
      "locally at: 5580\n",
      "locally at: 5590\n",
      "locally at: 5600\n",
      "locally at: 5610\n",
      "locally at: 5620\n",
      "locally at: 5630\n",
      "locally at: 5640\n",
      "locally at: 5650\n",
      "locally at: 5660\n",
      "locally at: 5670\n",
      "locally at: 5680\n",
      "locally at: 5690\n",
      "locally at: 5700\n",
      "locally at: 5710\n",
      "locally at: 5720\n",
      "locally at: 5730\n",
      "locally at: 5740\n",
      "locally at: 5750\n",
      "locally at: 5760\n",
      "locally at: 5770\n",
      "locally at: 5780\n",
      "locally at: 5790\n",
      "locally at: 5800\n",
      "locally at: 5810\n",
      "locally at: 5820\n",
      "locally at: 5830\n",
      "locally at: 5840\n",
      "locally at: 5850\n",
      "locally at: 5860\n",
      "locally at: 5870\n",
      "locally at: 5880\n",
      "locally at: 5890\n",
      "locally at: 5900\n",
      "locally at: 5910\n",
      "locally at: 5920\n",
      "locally at: 5930\n",
      "locally at: 5940\n",
      "locally at: 5950\n",
      "locally at: 5960\n",
      "locally at: 5970\n",
      "locally at: 5980\n",
      "locally at: 5990\n",
      "locally at: 6000\n",
      "locally at: 6010\n",
      "locally at: 6020\n",
      "locally at: 6030\n",
      "locally at: 6040\n",
      "locally at: 6050\n",
      "locally at: 6060\n",
      "locally at: 6070\n",
      "locally at: 6080\n",
      "locally at: 6090\n",
      "locally at: 6100\n",
      "locally at: 6110\n",
      "locally at: 6120\n",
      "locally at: 6130\n",
      "locally at: 6140\n",
      "locally at: 6150\n",
      "locally at: 6160\n",
      "locally at: 6170\n",
      "locally at: 6180\n",
      "locally at: 6190\n",
      "locally at: 6200\n",
      "locally at: 6210\n",
      "locally at: 6220\n",
      "locally at: 6230\n",
      "locally at: 6240\n",
      "locally at: 6250\n",
      "locally at: 6260\n",
      "locally at: 6270\n",
      "locally at: 6280\n",
      "locally at: 6290\n",
      "locally at: 6300\n",
      "locally at: 6310\n",
      "locally at: 6320\n",
      "locally at: 6330\n",
      "locally at: 6340\n",
      "locally at: 6350\n",
      "locally at: 6360\n",
      "locally at: 6370\n",
      "locally at: 6380\n",
      "locally at: 6390\n",
      "locally at: 6400\n",
      "locally at: 6410\n",
      "locally at: 6420\n",
      "locally at: 6430\n",
      "locally at: 6440\n",
      "locally at: 6450\n",
      "locally at: 6460\n",
      "locally at: 6470\n",
      "locally at: 6480\n",
      "locally at: 6490\n",
      "locally at: 6500\n",
      "locally at: 6510\n",
      "locally at: 6520\n",
      "locally at: 6530\n",
      "locally at: 6540\n",
      "locally at: 6550\n",
      "locally at: 6560\n",
      "locally at: 6570\n",
      "locally at: 6580\n",
      "locally at: 6590\n",
      "locally at: 6600\n",
      "locally at: 6610\n",
      "locally at: 6620\n",
      "locally at: 6630\n",
      "locally at: 6640\n",
      "locally at: 6650\n",
      "locally at: 6660\n",
      "locally at: 6670\n",
      "locally at: 6680\n",
      "locally at: 6690\n",
      "locally at: 6700\n",
      "locally at: 6710\n",
      "locally at: 6720\n",
      "locally at: 6730\n",
      "locally at: 6740\n",
      "locally at: 6750\n",
      "locally at: 6760\n",
      "locally at: 6770\n",
      "locally at: 6780\n",
      "locally at: 6790\n",
      "locally at: 6800\n",
      "locally at: 6810\n",
      "locally at: 6820\n",
      "locally at: 6830\n",
      "locally at: 6840\n",
      "locally at: 6850\n",
      "locally at: 6860\n",
      "locally at: 6870\n",
      "locally at: 6880\n",
      "locally at: 6890\n",
      "locally at: 6900\n",
      "locally at: 6910\n",
      "locally at: 6920\n",
      "locally at: 6930\n",
      "locally at: 6940\n",
      "locally at: 6950\n",
      "locally at: 6960\n",
      "locally at: 6970\n",
      "locally at: 6980\n",
      "locally at: 6990\n",
      "locally at: 7000\n",
      "locally at: 7010\n",
      "locally at: 7020\n",
      "locally at: 7030\n",
      "locally at: 7040\n",
      "locally at: 7050\n",
      "locally at: 7060\n",
      "locally at: 7070\n",
      "locally at: 7080\n",
      "locally at: 7090\n",
      "locally at: 7100\n",
      "locally at: 7110\n",
      "locally at: 7120\n",
      "locally at: 7130\n",
      "locally at: 7140\n",
      "locally at: 7150\n",
      "locally at: 7160\n",
      "locally at: 7170\n",
      "locally at: 7180\n",
      "locally at: 7190\n",
      "locally at: 7200\n",
      "locally at: 7210\n",
      "locally at: 7220\n",
      "locally at: 7230\n",
      "locally at: 7240\n",
      "locally at: 7250\n",
      "locally at: 7260\n",
      "locally at: 7270\n",
      "locally at: 7280\n",
      "locally at: 7290\n",
      "locally at: 7300\n",
      "locally at: 7310\n",
      "locally at: 7320\n",
      "locally at: 7330\n",
      "locally at: 7340\n",
      "locally at: 7350\n",
      "locally at: 7360\n",
      "locally at: 7370\n",
      "locally at: 7380\n",
      "locally at: 7390\n",
      "locally at: 7400\n",
      "locally at: 7410\n",
      "locally at: 7420\n",
      "locally at: 7430\n",
      "locally at: 7440\n",
      "locally at: 7450\n",
      "locally at: 7460\n",
      "locally at: 7470\n",
      "locally at: 7480\n",
      "locally at: 7490\n",
      "locally at: 7500\n",
      "locally at: 7510\n",
      "locally at: 7520\n",
      "locally at: 7530\n",
      "locally at: 7540\n",
      "locally at: 7550\n",
      "locally at: 7560\n",
      "locally at: 7570\n",
      "locally at: 7580\n",
      "locally at: 7590\n",
      "locally at: 7600\n",
      "locally at: 7610\n",
      "locally at: 7620\n",
      "locally at: 7630\n",
      "locally at: 7640\n",
      "locally at: 7650\n",
      "locally at: 7660\n",
      "locally at: 7670\n",
      "locally at: 7680\n",
      "locally at: 7690\n",
      "locally at: 7700\n",
      "locally at: 7710\n",
      "locally at: 7720\n",
      "locally at: 7730\n",
      "locally at: 7740\n",
      "locally at: 7750\n",
      "locally at: 7760\n",
      "locally at: 7770\n",
      "locally at: 7780\n",
      "locally at: 7790\n",
      "locally at: 7800\n",
      "locally at: 7810\n",
      "locally at: 7820\n",
      "locally at: 7830\n",
      "locally at: 7840\n",
      "locally at: 7850\n",
      "locally at: 7860\n",
      "locally at: 7870\n",
      "locally at: 7880\n",
      "locally at: 7890\n",
      "locally at: 7900\n",
      "locally at: 7910\n",
      "locally at: 7920\n",
      "locally at: 7930\n",
      "locally at: 7940\n",
      "locally at: 7950\n",
      "locally at: 7960\n",
      "locally at: 7970\n",
      "locally at: 7980\n",
      "locally at: 7990\n",
      "locally at: 8000\n",
      "locally at: 8010\n",
      "locally at: 8020\n",
      "locally at: 8030\n",
      "locally at: 8040\n",
      "locally at: 8050\n",
      "locally at: 8060\n",
      "locally at: 8070\n",
      "locally at: 8080\n",
      "locally at: 8090\n",
      "locally at: 8100\n",
      "locally at: 8110\n",
      "locally at: 8120\n",
      "locally at: 8130\n",
      "locally at: 8140\n",
      "locally at: 8150\n",
      "locally at: 8160\n",
      "locally at: 8170\n",
      "locally at: 8180\n",
      "locally at: 8190\n",
      "locally at: 8200\n",
      "locally at: 8210\n",
      "locally at: 8220\n",
      "locally at: 8230\n",
      "locally at: 8240\n",
      "locally at: 8250\n",
      "locally at: 8260\n",
      "locally at: 8270\n",
      "locally at: 8280\n",
      "locally at: 8290\n",
      "locally at: 8300\n",
      "locally at: 8310\n",
      "locally at: 8320\n",
      "locally at: 8330\n",
      "locally at: 8340\n",
      "locally at: 8350\n",
      "locally at: 8360\n",
      "locally at: 8370\n",
      "locally at: 8380\n",
      "locally at: 8390\n",
      "locally at: 8400\n",
      "locally at: 8410\n",
      "locally at: 8420\n",
      "locally at: 8430\n",
      "locally at: 8440\n",
      "locally at: 8450\n",
      "locally at: 8460\n",
      "locally at: 8470\n",
      "locally at: 8480\n",
      "locally at: 8490\n",
      "locally at: 8500\n",
      "locally at: 8510\n",
      "locally at: 8520\n",
      "locally at: 8530\n",
      "locally at: 8540\n",
      "locally at: 8550\n",
      "locally at: 8560\n",
      "locally at: 8570\n",
      "locally at: 8580\n",
      "locally at: 8590\n",
      "locally at: 8600\n",
      "locally at: 8610\n",
      "locally at: 8620\n",
      "locally at: 8630\n",
      "locally at: 8640\n",
      "locally at: 8650\n",
      "locally at: 8660\n",
      "locally at: 8670\n",
      "locally at: 8680\n",
      "locally at: 8690\n",
      "locally at: 8700\n",
      "locally at: 8710\n",
      "locally at: 8720\n",
      "locally at: 8730\n",
      "locally at: 8740\n",
      "locally at: 8750\n",
      "locally at: 8760\n",
      "locally at: 8770\n",
      "locally at: 8780\n",
      "locally at: 8790\n",
      "locally at: 8800\n",
      "locally at: 8810\n",
      "locally at: 8820\n",
      "locally at: 8830\n",
      "locally at: 8840\n",
      "locally at: 8850\n",
      "locally at: 8860\n",
      "locally at: 8870\n",
      "locally at: 8880\n",
      "locally at: 8890\n",
      "locally at: 8900\n",
      "locally at: 8910\n",
      "locally at: 8920\n",
      "locally at: 8930\n",
      "locally at: 8940\n",
      "locally at: 8950\n",
      "locally at: 8960\n",
      "locally at: 8970\n",
      "locally at: 8980\n",
      "locally at: 8990\n",
      "locally at: 9000\n",
      "locally at: 9010\n",
      "locally at: 9020\n",
      "locally at: 9030\n",
      "locally at: 9040\n",
      "locally at: 9050\n",
      "locally at: 9060\n",
      "locally at: 9070\n",
      "locally at: 9080\n",
      "locally at: 9090\n",
      "locally at: 9100\n",
      "locally at: 9110\n",
      "locally at: 9120\n",
      "locally at: 9130\n",
      "locally at: 9140\n",
      "locally at: 9150\n",
      "locally at: 9160\n",
      "locally at: 9170\n",
      "locally at: 9180\n",
      "locally at: 9190\n",
      "locally at: 9200\n",
      "locally at: 9210\n",
      "locally at: 9220\n",
      "locally at: 9230\n",
      "locally at: 9240\n",
      "locally at: 9250\n",
      "locally at: 9260\n",
      "locally at: 9270\n",
      "locally at: 9280\n",
      "locally at: 9290\n",
      "locally at: 9300\n",
      "locally at: 9310\n",
      "locally at: 9320\n",
      "locally at: 9330\n",
      "locally at: 9340\n",
      "locally at: 9350\n",
      "locally at: 9360\n",
      "locally at: 9370\n",
      "locally at: 9380\n",
      "locally at: 9390\n",
      "locally at: 9400\n",
      "locally at: 9410\n",
      "locally at: 9420\n",
      "locally at: 9430\n",
      "locally at: 9440\n",
      "locally at: 9450\n",
      "locally at: 9460\n",
      "locally at: 9470\n",
      "locally at: 9480\n",
      "locally at: 9490\n",
      "locally at: 9500\n",
      "locally at: 9510\n",
      "locally at: 9520\n",
      "locally at: 9530\n",
      "locally at: 9540\n",
      "locally at: 9550\n",
      "locally at: 9560\n",
      "locally at: 9570\n",
      "locally at: 9580\n",
      "locally at: 9590\n",
      "locally at: 9600\n",
      "locally at: 9610\n",
      "locally at: 9620\n",
      "locally at: 9630\n",
      "locally at: 9640\n",
      "locally at: 9650\n",
      "locally at: 9660\n",
      "locally at: 9670\n",
      "locally at: 9680\n",
      "locally at: 9690\n",
      "locally at: 9700\n",
      "locally at: 9710\n",
      "locally at: 9720\n",
      "locally at: 9730\n",
      "locally at: 9740\n",
      "locally at: 9750\n",
      "locally at: 9760\n",
      "locally at: 9770\n",
      "locally at: 9780\n",
      "locally at: 9790\n",
      "locally at: 9800\n",
      "locally at: 9810\n",
      "locally at: 9820\n",
      "locally at: 9830\n",
      "locally at: 9840\n",
      "locally at: 9850\n",
      "locally at: 9860\n",
      "locally at: 9870\n",
      "locally at: 9880\n",
      "locally at: 9890\n",
      "locally at: 9900\n",
      "locally at: 9910\n",
      "locally at: 9920\n",
      "locally at: 9930\n",
      "locally at: 9940\n",
      "locally at: 9950\n",
      "locally at: 9960\n",
      "locally at: 9970\n",
      "locally at: 9980\n",
      "locally at: 9990\n"
     ]
    }
   ],
   "source": [
    "#Instead of list comprehension, I use an explicit for loop to show progress/user feedback as classification takes place\n",
    "predictions = np.zeros(len(testYArr))\n",
    "for i in range(len(testYArr)):\n",
    "    predictions[i] = predictOneDigit(10,trainX,trainY,testXArr[i])\n",
    "    if(i % 10 == 0):\n",
    "        print(\"locally at:\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 % 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, ..., 6])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.0, 2.0, 1.0, 0.0, 4.0, 1.0, 4.0, 9.0, 5.0, 9.0]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, ..., 6])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = testYArr\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "#predictions\n",
    "#correct\n",
    "scipy.io.savemat('test.mat', dict(predictions=predictions, correct=correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testYArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting a single prediction outside of the encapsulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980.683972773042"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance(testXArr[3],trainX[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = [euclidean_distance(testXArr[3],trainX[i]) for i in range(len(trainX))]\n",
    "len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2.56e+03],\n",
       "       [0, 1.98e+03],\n",
       "       [4, 3.02e+03],\n",
       "       [1, 3.1e+03],\n",
       "       [9, 2.71e+03],\n",
       "       [2, 2.62e+03],\n",
       "       [1, 2.81e+03],\n",
       "       [3, 2.82e+03],\n",
       "       [1, 2.84e+03],\n",
       "       [4, 2.86e+03]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tupledDistances = np.array(list(zip(trainY,distances)))\n",
    "tupledDistances[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_second = sorted(tupledDistances, key=lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1.22e+03]),\n",
       " array([0, 1.23e+03]),\n",
       " array([0, 1.24e+03]),\n",
       " array([0, 1.25e+03]),\n",
       " array([0, 1.3e+03]),\n",
       " array([0, 1.3e+03]),\n",
       " array([0, 1.3e+03]),\n",
       " array([0, 1.31e+03]),\n",
       " array([0, 1.32e+03]),\n",
       " array([0, 1.32e+03])]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_by_second[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "kLabels = [label for (label,_) in sorted_by_second[:k]]\n",
    "kLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findMajority(kLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering data type for Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting view\n",
    "np.set_printoptions(edgeitems=1, linewidth=500, \n",
    "    formatter=dict(float=lambda x: \"%.3g\" % x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60, 224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252, 252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253, 253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252, 179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,  84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,  28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,   0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,   0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,   0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,   0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85, 178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252, 252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252, 233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,  37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 150, 253, 202,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 197, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 190, 251, 251, 251, 253, 169, 109,  62,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 251, 251, 251, 251, 253, 251, 251, 220,  51,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 255, 253, 253, 253, 253, 234, 222, 253, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  63, 221, 253, 251, 251, 251, 147,  77,  62, 128, 251, 251, 105,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  32, 231, 251, 253, 251, 220, 137,  10,   0,   0,  31, 230, 251, 243, 113,   5,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 188,  20,   0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 201,  30,   0,   0,   0,   0,   0,   0,  31, 200, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0,  32, 202, 255, 253, 164,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 251, 251,   0,   0,   0,   0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0,   0,  21,  63, 231, 251, 253, 230,  30,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0,   0, 144, 251, 251, 251, 221,  61,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0, 182, 221, 251, 251, 251, 180,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 218, 253, 253,  73,  73, 228, 253, 253, 255, 253, 253, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 113, 251, 251, 253, 251, 251, 251, 251, 253, 251, 251, 251, 147,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  31, 230, 251, 253, 251, 251, 251, 251, 253, 230, 189,  35,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  62, 142, 253, 251, 251, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  72, 174, 251, 173,  71,  72,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 150, 253, 151, 128,   3,  97, 206,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 251, 203,  15, 111,   4,   4,  19,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 197, 197,  24,   0, 111,  17,  23,   4, 199, 250,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 180, 191,  27, 255,   0, 173, 163, 234,   4,   3, 134,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253,  88, 255, 255, 255,   0, 255, 255, 124, 118,   3,  89,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 204,  15,   0,   0,  63, 120, 225,  25, 206, 174,   1,  88,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  63, 173,  15, 255, 255,  72, 135,   2, 197, 107, 251, 251, 108,  13, 206,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  32, 193,  86,   0,  18,  12,  53,  10,   0,   0,  31, 230, 251, 246, 117,  96,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  30,  73, 255,  13, 117,   1, 228,   0,   0,   0,   0, 109, 251,   0, 255,  96,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 236, 255, 255, 138,  30,   0,   0,   0,   0,   0,   0,  31, 200,   0, 255,  96,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  95,   0,  63,   0,   0,   0,   0,   0,   0,   0,   0,  32, 202,   0,   0, 224,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 180, 150, 255, 139,   0,   0,   0,   0,   0,   0,   0,   0, 109, 251,   0, 255, 143,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 171, 221,  21, 226,   0,   0,   0,   0,   0,   0,  21,  63, 224, 116,   0,  44,  18,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 171, 221,  28, 251,   0,   0,   0,   0,   0,   0, 144, 244, 120, 255, 252, 246,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 171, 221, 106, 251,   0,   0,   0,   0,   0, 182, 173,  86, 255,  78, 180,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 170, 221,  28, 253,  73,  73, 228, 253, 253, 141,  15,   0,  91, 253,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 171, 117,   2, 105, 205, 222, 166,  73,  26,   0,  28,  84, 195, 147,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 171,  35, 234, 255,  24,  36, 255, 255, 255,  57, 100, 189,  35,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 228,  57,  66, 146,   0, 255, 255,  18, 106, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 231, 128,   4,  75, 178, 110, 136,  71,  72,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX[3]-trainX[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a valid form of euclidean distance. \n",
    "\n",
    "This is because uint8 ranges from 0-256. As such, we cannot acquire negative values. Overflow leaves values of 199, which are overestimations of error at a location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observe:\n",
    "testX[3][6][20]-trainX[1][6][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 150, 253, 202,  31,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 197, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 190, 251, 251, 251, 253, 169, 109,  62,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 251, 251, 251, 251, 253, 251, 251, 220,  51,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 255, 253, 253, 253, 253, 234, 222, 253, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  63, 221, 253, 251, 251, 251, 147,  77,  62, 128, 251, 251, 105,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  32, 231, 251, 253, 251, 220, 137,  10,   0,   0,  31, 230, 251, 243, 113,   5,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 253, 188,  20,   0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 251, 251, 201,  30,   0,   0,   0,   0,   0,   0,  31, 200, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  37, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0,  32, 202, 255, 253, 164,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 140, 251, 251,   0,   0,   0,   0,   0,   0,   0,   0, 109, 251, 253, 251,  35,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0,   0,  21,  63, 231, 251, 253, 230,  30,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0,   0, 144, 251, 251, 251, 221,  61,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 217, 251, 251,   0,   0,   0,   0,   0, 182, 221, 251, 251, 251, 180,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 218, 253, 253,  73,  73, 228, 253, 253, 255, 253, 253, 253, 253,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 113, 251, 251, 253, 251, 251, 251, 251, 253, 251, 251, 251, 147,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  31, 230, 251, 253, 251, 251, 251, 251, 253, 230, 189,  35,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  62, 142, 253, 251, 251, 251, 251, 253, 107,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  72, 174, 251, 173,  71,  72,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert test to int32\n",
    "TestXNew = testX[3].astype(np.int32)\n",
    "TestXNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   11,  150,  253,  151, -128, -253, -159,  -50,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   37,  251,  203,   15, -145, -252, -252, -237,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   21,  197,  197,   24,    0, -145, -239, -233, -252,  -57,   -6,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  110,  180,  191,   27,   -1,    0,  -83,  -93,  -22, -252, -253, -122,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  253,   88,   -1,   -1,   -1,    0,   -1,   -1,  124, -138, -253, -167,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,  182,  204,   15,    0,    0,   63,  120,  -31,   25,  206,  174, -255, -168,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,   63,  173,   15,   -1,   -1,   72,  135,    2,  -59,  107,  251,  251, -148, -243,  -50,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,   32,  193,   86,    0,   18,   12,   53,   10,    0,    0,   31,  230,  251,  -10, -139, -160,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,   30,   73,   -1,   13,  117,    1,  -28,    0,    0,    0,    0,  109,  251,    0,   -1, -160,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,  -20,   -1,   -1,  138,   30,    0,    0,    0,    0,    0,    0,   31,  200,    0,   -1, -160,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, -161,    0,   63,    0,    0,    0,    0,    0,    0,    0,    0,   32,  202,    0,    0,  -32,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  -76, -106,   -1,  139,    0,    0,    0,    0,    0,    0,    0,    0,  109,  251,    0,   -1, -113,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  -85,  -35,   21,  226,    0,    0,    0,    0,    0,    0,   21,   63,  224,  116,    0,   44,   18,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  -85,  -35,   28,  251,    0,    0,    0,    0,    0,    0,  144,  244,  120,   -1,   -4,  -10,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  -85,  -35,  106,  251,    0,    0,    0,    0,    0,  182,  173,   86,   -1,   78,  180,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  -86,  -35,   28,  253,   73,   73,  228,  253,  253,  141,   15,    0,   91,  253,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  -85, -139,    2,  105,  205,  222,  166,   73,   26,    0,   28,   84,  195,  147,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  -85, -221,  -22,   -1,   24,   36,   -1,   -1,   -1,   57,  100,  189,   35,   10,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,  -28, -199, -190, -110,    0,   -1,   -1,   18,  106,  253,  107,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,  -25, -128, -252, -181,  -78,  110,  136,   71,   72,   30,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestXNew - trainX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980.683972773042"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Further verification if Euclidean norm versus my manual calculation\n",
    "from numpy import linalg as LA\n",
    "heyo = TestXNew - trainX[1]\n",
    "LA.norm(heyo,'fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestXNew = testX[3].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980.683972773042"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seems legit.\n",
    "np.sqrt(np.sum((trainX[1]-TestXNew)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom K By Intuition\n",
    "Even if our solution is not perfectly efficient, it should save time by reducing the complexity from sorting an ENTIRE array N times to K-Smallest N times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tupledVals = [(0,1.2),(0,0.8),(1,2.2),(2,3.2),(0,0.2),(4,72),(6,2.1),(9,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smallestKInTuple(inputList,k):\n",
    "    \"\"\"\n",
    "    INPUT: An array or list of TUPLES\n",
    "    OUTPUT: smallest k elements\n",
    "    Functionality: Does so by modified selection sort.\n",
    "    Dependancy: I use numpy for argmin.\n",
    "    \"\"\"\n",
    "    #Store into temp array\n",
    "    temp = inputList[0:k]\n",
    "    \n",
    "    #Find max of temp array\n",
    "    maxTemp = max(temp, key = lambda t: t[1])\n",
    "    maxVal = maxTemp[1]\n",
    "    \n",
    "    #for inputLIst[k:]\n",
    "    for i in range(k,len(inputList)):\n",
    "        #if the value at i in inputList[k:n] is less\n",
    "        if(inputList[i][1] < maxVal):\n",
    "            #Swap that value with current max in our k list\n",
    "            \n",
    "            #This is to determine the index where we have our max location\n",
    "            p = -1\n",
    "            for tupleTemp in temp:\n",
    "                p = p+1\n",
    "                \n",
    "                if(tupleTemp[1] == maxVal):\n",
    "                    maxLocation = p\n",
    "            \n",
    "            \n",
    "            temp[maxLocation] = inputList[i]\n",
    "            \n",
    "            #New max\n",
    "            maxTemp = max(temp, key = lambda t: t[1])\n",
    "            maxVal = maxTemp[1]\n",
    "            \n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.2), (0, 0.8), (0, 0.2)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallestKInTuple(tupledVals,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tupledVals[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1.2), (0, 0.8), (1, 2.2)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets try with k = 3\n",
    "k=3\n",
    "tupledVals[0:k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hey = max(tupledVals, key = lambda t: t[1])\n",
    "hey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hey[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3.2)\n",
      "(0, 0.2)\n",
      "(4, 0.75)\n",
      "(6, 2.1)\n",
      "(9, 10)\n"
     ]
    }
   ],
   "source": [
    "for i in range(k,len(tupledVals)):\n",
    "    print(tupledVals[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tupledVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 3, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = distances[0:5]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minTemp = min(temp)\n",
    "minTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for x in distances[5:]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,len(distances)):\n",
    "    print(distances[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
